---
title: "MySQL 进阶：从原理到实战"
excerpt: "深入理解 MySQL 体系结构、索引优化、Buffer Pool 机制、事务隔离级别、锁机制等核心知识点"
date: 2026-02-08 00:00:00 +0800
categories: 数据库
tags:
  - MySQL
  - 索引优化
  - 事务
  - 锁机制
  - 性能调优
toc: true
toc_sticky: true
author_profile: true
---


![NotebookLM Mind Map (2)](/assets/images/mysql/NotebookLM Mind Map (2).png)

## 目录

### 基础原理
- [Mysql体系结构](#mysql体系结构)
- [索引失效](#-索引失效)
- [count（*）和count（1）的区别](#count和count1的区别)
- [如何优化count(*)](#如何优化count)
- [索引下推](#索引下推也就是将server层筛选数据的工作下推到引擎层处理)
- [Buffer Pool](#buffer-pool)
  - [free链表（空闲链表）](#free链表空闲链表)
  - [flush链表（脏页链表）](#flush链表脏页链表)
  - [简单的LRU链表（淘汰表）](#简单的lru链表淘汰表)
  - [划分区域的LRU链表](#划分区域的lru链表)
  - [有了冷热分区的lru链表的缓存策略](#有了冷热分区的lru链表的缓存策略)
  - [更进一步优化LRU链表](#更进一步优化lru链表)
  - [刷新脏页到磁盘](#刷新脏页到磁盘)
  - [多个Buffer Pool实例](#多个buffer-pool实例)
- [Change Buffer](#change-buffer)
- [Doublewrite Buffer](#-详解-doublewrite-buffer)
- [⚙️ InnoDB 性能调优核心参数](#️-innodb-性能调优核心参数)
  - [Buffer Pool 相关](#buffer-pool-相关)
  - [Redo Log 相关](#redo-log-相关)
  - [Binlog 相关](#binlog-相关)
  - [Change Buffer 相关](#change-buffer-相关)
  - [Doublewrite Buffer 相关](#doublewrite-buffer-相关)
  - [锁相关](#锁相关)
  - [其他核心参数](#其他核心参数)

### 事务与锁
- [事务](#事务)
  - [事务AICD四个特性](#事务aicd四个特性)
  - [显示/隐式事务](#显示隐式事务)
  - [事务隔离级别](#事务隔离级别标准情况下)
  - [MVCC](#mvcc)
    - [快照读和当前读](#1快照读和当前读)
    - [Read View](#2-read-view)
- [锁](#锁)
  - [全局锁](#31-全局锁)
  - [表级锁](#32-表级锁)
  - [行级锁](#33-行级锁)
    - [Record Lock（记录锁）](#record-lock记录锁)
    - [Gap Lock（间隙锁）](#gap-lock间隙锁)
    - [Next-Key Lock（临键锁）](#next-key-lock临键锁)
    - [插入意向锁](#插入意向锁)
  - [MySql是怎么加行级锁的](#mysql是怎么加行级锁的)
    - [唯一索引等值查询](#唯一索引等值查询)
    - [唯一索引范围查询](#唯一索引范围查询)
    - [非唯一索引等值查询](#非唯一索引等值查询)

### 日志系统
- [日志](#日志)
  - [undo log](#undo-log)
  - [redo log](#redo-log)
  - [bin log](#bin-log)
- [两阶段提交](#两阶段提交)
  - [为什么要二阶段提交？？](#为什么要二阶段提交)
  - [写入机制](#写入机制)
  - [binlog刷盘机制](#binlog刷盘机制)
  - [binlog与redolog对比](#binlog与redolog对比)
  - [两阶段提交的原理](#两阶段提交的原理)
  - [两阶段提交的问题](#两阶段提交的问题)

### 高可用
- [主从复制](#主从复制)
- [分库分表](#分库分表)

### 性能优化
- [慢查询日志](#慢查询日志)
- [🔍 Join 优化实战案例](#-join-优化实战案例)

### 面试专题
- [不熟悉的面试题](#不熟悉的面试题)
  - [Exist和In的区别？](#exist和in的区别)
  - [Innodb中是如何保存数据的null值的](#innodb中是如何保存数据的null值的)
  - [为什么隐藏字段的信息要逆序存放？](#为什么隐藏字段的信息要逆序存放)
  - [假如说一个字段是varchar(10),但它其实只有6个字节,那他在内存中占的存储空间是多少?在文件中占的存储空间是多少?](#假如说一个字段是varchar10但它其实只有6个字节那他在内存中占的存储空间是多少在文件中占的存储空间是多少)
- [🔥 MySQL Top 20 面试题速查](#-mysql-top-20-面试题速查)
  - [索引原理篇（1-5）](#一索引原理篇1-5)
  - [事务与锁篇（6-10）](#二事务与锁篇6-10)
  - [日志与高可用篇（11-15）](#三日志与高可用篇11-15)
  - [实战优化篇（16-20）](#四实战优化篇16-20)
  - [面试准备清单](#-面试准备清单)

---

## Mysql体系结构

连接层：负责授权认证、权限控制、配置链接，控制连接数等

服务层：主要完成大多数的核心服务功能，比如sql接口、缓存查询、SQL分析和优化、部分内置函数的执行，还有所有的跨引擎的功能如  过程、函数等

引擎层：想用哪个就换哪个，真正负责了数据的存储和提取（引擎是基于表的，同一个数据库可以使用不同的引擎）

【注意】：索引index是在引擎层实现的，不同的引擎，索引的结构是不一样的

存储层：将数据存储在文件系统之上，并完成与存储引擎的交互



![image-20250421195841196](/assets/images/mysql/image-20250421195841196.png)

 ## 索引失效

首先要明确一点： MySql中的索引是使用B+树来存储的

1、使用左或者左右模糊匹配会导致失效

2、对索引使用函数也会失效。因为索引保存的是索引字段的原始值，对字段使用函数可以理解为有了个新字段，这个新字段并没有索引，所以会导致失效。如果可以可以在建表时就使用函数方式将这个列建出来

![image-20250525115110616](/assets/images/mysql/image-20250525115110616.png)

3、对索引进行表达式计算，例如 ... where id + 1 = 10,这种就无法走索引，但改成id = 10-1就能走了

4、对索引隐式类型转换。如果表中某字段是字符串类型，但在我们查询时使用了数字类型

如 where phone = 13000000001，这种，MySql就会把原来表中的每一个记录先转成数字，再比较，自然无法走索引。

**MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较**

5、联合索引非最左匹配

6、where子句中的or。 如果or前面的字段是有索引的，而后面的字段没有索引，就会导致前面的字段索引失效

因为or的含义就是两个只要满足一个即可，因此只有一个列是索引列是没意义的，要两个都是索引列才可以。

只要有一个不是索引列，就会进行全表扫描。

7、范围查询后字段的索引失效，比如<, >符号或者between等。

要解决该问题就要在创建索引的时候把需要范围查询的字段放在最后

8、不等于 != 或者 <> 也会导致索引失效

9、is null可以使用索引，is not null无法使用索引

所以最好在建表时就对某个字段约束好not null

10、在`MySQL`中还有一种特殊情况会导致索引失效，也就是当走索引扫描的行数超过表行数的`30%`时，`MySQL`会默认放弃索引查询，转而使用全表扫描的方式检索数据，因此这种情况下走索引的随机磁盘`IO`，反而不一定有全表的顺序磁盘`IO`快。

## count（*）和count（1）的区别

首先要知道count是什么，他代表的是，在符合条件的记录中，该函数指定的不为NULL的记录有多少个

1、count（1）：

- 只有主键索引，没有二级索引时：遍历主键索引然后，每次**不读取值**，因为1就是1，他不是NULL
- 有二级索引时，他就会遍历二级索引

2、count(主键字段)：

- 只有主键索引，没有二级索引时，就会遍历主键索引然后，每次都要读取一下值，并判断是否为null
- 有二级索引时，他就会遍历二级索引，因为二级索引的B+树占得资源少，成本低，所以优化器选择这样做

3、count（*）：执行时候会自动被优化成count（0）所以和count（1）没区别

如果有多个二级索引，优化器会自动选择字段长度最小的二级索引进行扫描

4、count（普通字段）：全表扫描，效率最低。

![image-20250525121710557](/assets/images/mysql/image-20250525121710557.png)

## 如何优化count(*)?

对于比较大的表，使用count也很慢

1、可以使用近似值，使用 show table status 或者 explain 命令来表进行估算

2、额外维护一个计数表，每次改变就去修改该表

## 索引下推（也就是将`Server`层筛选数据的工作，下推到引擎层处理）

![image-20250525125627804](/assets/images/mysql/image-20250525125627804.png)

## Buffer Pool

![image-20250807133030271](/assets/images/mysql/image-20250807133030271.png)

  `InnoDB`作为存储引擎的表来说，不管是用于存储用户数据的索引（包括聚簇索引和二级索引），还是各种系统数据，都是以`页`的形式存放在`表空间`中的，而所谓的`表空间`只不过是`InnoDB`对文件系统上一个或几个实际文件的抽象。`InnoDB`存储引擎在处理客户端的请求时，当需要访问某个页的数据时，就会把完整的页的数据全部加载到内存中，也就是说**即使我们只需要访问一个页的一条记录，那也需要先把整个页的数据加载到内存中**。将整个页加载到内存中后就可以进行读写访问了，在进行完读写访问之后并不着急把该页对应的内存空间释放掉，而是将其`缓存`起来，这样将来有请求再次访问该页面时，就可以省去磁盘`IO`的开销了。

在`MySQL`服务器启动的时候就向操作系统申请了一片连续的内存，他们给这片内存起了个名，叫做`Buffer Pool`

整个`Buffer Pool`对应的内存空间看起来就是这样的：

![image-20250525171611062](/assets/images/mysql/image-20250525171611062.png)

### free链表（空闲链表）

  我们最好在某个地方记录一下Buffer Pool中哪些缓存页是可用的，这个时候缓存页对应的`控制块`就派上大用场了，我们可以把所有空闲的缓存页对应的控制块作为一个节点放到一个链表中，这个链表也可以被称作`free链表`（或者说空闲链表）。刚刚完成初始化的`Buffer Pool`中所有的缓存页都是空闲的，所以每一个缓存页对应的控制块都会被加入到`free链表`中

![image-20250525171851067](/assets/images/mysql/image-20250525171851067.png)

  用`表空间号 + 页号`作为`key`，`缓存页`作为`value`创建一个哈希表，在需要访问某个页的数据时，先从哈希表中根据`表空间号 + 页号`看看有没有对应的缓存页，如果有，直接使用该缓存页就好，如果没有，那就从`free链表`中选一个空闲的缓存页，然后把磁盘中对应的页加载到该缓存页的位置。

### flush链表（脏页链表）

  如果我们修改了`Buffer Pool`中某个缓存页的数据，那它就和磁盘上的页不一致了，这样的缓存页也被称为`脏页`（英文名：`dirty page`）。每次修改缓存页后，我们并不着急立即把修改同步到磁盘上，而是在未来的某个时间点进行同步。

  所以，我们不得不再创建一个存储脏页的链表，凡是修改过的缓存页对应的控制块都会作为一个节点加入到一个链表中，因为这个链表节点对应的缓存页都是需要被刷新到磁盘上的，所以也叫`flush链表`。

![image-20250525172511056](/assets/images/mysql/image-20250525172511056.png)

### 简单的LRU链表（淘汰表）

当`Buffer Pool`中不再有空闲的缓存页时，就需要淘汰掉部分最近很少使用的缓存页。

​    我们可以再创建一个链表，由于这个链表是为了`按照最近最少使用`的原则去淘汰缓存页的，所以这个链表可以被称为`LRU链表`（LRU的英文全称：Least Recently Used）。

当我们需要访问某个页时，可以这样处理`LRU链表`：

- 如果该页不在`Buffer Pool`中，在把该页从磁盘加载到`Buffer Pool`中的缓存页时，就把该缓存页对应的`控制块`作为节点塞到链表的头部。
- 如果该页已经缓存在`Buffer Pool`中，则直接把该页对应的`控制块`移动到`LRU链表`的头部。

  也就是说：只要我们使用到某个缓存页，就把该缓存页调整到`LRU链表`的头部，这样`LRU链表`尾部就是最近最少使用的缓存页，所以当`Buffer Pool`中的空闲缓存页使用完时，就到`LRU链表`的尾部找些缓存页淘汰。

### 划分区域的LRU链表

- 情况一：`InnoDB`提供了一个看起来比较贴心的服务——`预读`（英文名：`read ahead`）。所谓`预读`，就是`InnoDB`认为执行当前的请求可能之后会读取某些页面，就预先把它们加载到`Buffer Pool`中。根据触发方式的不同，`预读`又可以细分为下面两种：

  - 线性预读

    设计`InnoDB`的大佬提供了一个系统变量`innodb_read_ahead_threshold`，如果顺序访问了某个区（`extent`）的页面超过这个系统变量的值，就会触发一次`异步`读取下一个区中全部的页面到`Buffer Pool`的请求，注意`异步`读取意味着从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。

  - 随机预读

    如果`Buffer Pool`中已经缓存了某个区的13个连续的页面，不论这些页面是不是顺序读取的，都会触发一次`异步`读取本区中所有其的页面到`Buffer Pool`的请求。设计`InnoDB`的大佬同时提供了`innodb_random_read_ahead`系统变量，它的默认值为`OFF`，也就意味着`InnoDB`并不会默认开启随机预读的功能，如果我们想开启该功能，可以通过修改启动参数或者直接使用`SET GLOBAL`命令把该变量的值设置为`ON`。

      `预读`本来是个好事儿，如果预读到`Buffer Pool`中的页成功的被使用到，那就可以极大的提高语句执行的效率。可是如果用不到呢？这些预读的页都会放到`LRU`链表的头部，但是如果此时`Buffer Pool`的容量不太大而且很多预读的页面都没有用到的话，这就会导致处在`LRU链表`尾部的一些缓存页会很快的被淘汰掉，**会大大降低缓存命中率**。

- 情况二：执行**全表扫描**的查询语句（比如没有建立合适的索引或者压根儿没有WHERE子句的查询）。

  扫描全表意味着什么？意味着将访问到该表所在的所有页！假设这个表中记录非常多的话，那该表会占用特别多的`页`，当需要访问这些页时，会把它们统统都加载到`Buffer Pool`中，这也就意味着吧唧一下，`Buffer Pool`中的所有页都被换了一次血，其他查询语句在执行时又得执行一次从磁盘加载到`Buffer Pool`的操作。而这种全表扫描的语句执行的频率也不高，每次执行都要把`Buffer Pool`中的缓存页换一次血，这严重的影响到其他查询对 `Buffer Pool`的使用，从而大大降低了缓存命中率。



因为有这两种情况的存在，所以设计`InnoDB`的大佬把这个`LRU链表`按照**一定比例**分成两截，分别是：

- 一部分存储使用频率非常高的缓存页，所以这一部分链表也叫做`热数据`，或者称`young区域`。
- 另一部分存储使用频率不是很高的缓存页，所以这一部分链表也叫做`冷数据`，或者称`old区域`。

![image-20250525173739899](/assets/images/mysql/image-20250525173739899.png)

### 有了冷热分区的`LRU`链表的缓存策略

- 针对预读的页面可能不进行后续访情况的优化

  当磁盘上的某个页面在初次加载到Buffer Pool中的某个缓存页时，该缓存页对应的控制块会被放到old区域的头部。这样针对预读到`Buffer Pool`却不进行后续访问的页面就会被逐渐从`old`区域逐出，而不会影响`young`区域中被使用比较频繁的缓存页。

- 针对全表扫描时，短时间内访问大量使用频率非常低的页面情况的优化

  在进行全表扫描时，虽然首次被加载到`Buffer Pool`的页被放到了`old`区域的头部，但是后续会被马上访问到，每次进行访问的时候又会把该页放到`young`区域的头部，这样仍然会把那些使用频率比较高的页面给顶下去。

  为了处理这种情况，大佬规定，在对某个处在`old`区域的缓存页进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间**在某个时间间隔内**，那么该页面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部。上述的这个间隔时间是由系统变量`innodb_old_blocks_time`控制的，默认值是1000ms

### 更进一步优化LRU链表

  对于`young`区域的缓存页来说，我们每次访问一个缓存页就要把它移动到`LRU链表`的头部，这样开销太大了，毕竟在`young`区域的缓存页都是热点数据，也就是可能被经常访问的，这样频繁的对`LRU链表`进行节点移动操作不太好。

是的，为了解决这个问题其实我们还可以提出一些优化策略，比如**只有被访问的缓存页位于`young`区域的`1/4`的后边，才会被移动到`LRU链表`头部**，这样就可以降低调整`LRU链表`的频率，从而提升性能（也就是说如果某个缓存页对应的节点在`young`区域的`1/4`中，再次访问该缓存页时也不会将其移动到`LRU`链表头部）。

### 刷新脏页到磁盘

  后台有专门的线程每隔一段时间负责把脏页刷新到磁盘，这样可以不影响用户线程处理正常的请求。主要有两种刷新路径：

- 从`LRU链表`的冷数据中刷新一部分页面到磁盘。

  后台线程会**定时**从`LRU链表`尾部开始扫描一些页面，扫描的页面数量可以通过系统变量`innodb_lru_scan_depth`来指定，**如果从里边儿发现脏页**，会把它们刷新到磁盘。这种刷新页面的方式被称之为`BUF_FLUSH_LRU`。

- 从`flush链表`中刷新一部分页面到磁盘。

  后台线程也会定时从`flush链表`中刷新一部分页面到磁盘，刷新的速率取决于当时系统是不是很繁忙。这种刷新页面的方式被称之为`BUF_FLUSH_LIST`。

    有时候后台线程刷新脏页的进度比较慢，导致用户线程在准备加载一个磁盘页到`Buffer Pool`时没有可用的缓存页，这时就会尝试看看`LRU链表`尾部有没有可以直接释放掉的未修改页面，如果没有的话会不得不将`LRU链表`尾部的一个脏页同步刷新到磁盘（和磁盘交互是很慢的，这会降低处理用户请求的速度）。这种刷新单个页面到磁盘中的刷新方式被称之为`BUF_FLUSH_SINGLE_PAGE`。

  当然，有时候系统特别繁忙时，也可能出现用户线程批量的从`flush链表`中刷新脏页的情况，很显然在处理用户请求过程中去刷新脏页是一种严重降低处理速度的行为（毕竟磁盘的速度慢的要死），这属于一种迫不得已的情况。

### 多个Buffer Pool实例

  我们上面说过，`Buffer Pool`本质是`InnoDB`向操作系统申请的一块连续的内存空间，在多线程环境下，访问`Buffer Pool`中的各种链表都需要加锁处理什么的，在`Buffer Pool`特别大而且多线程并发访问特别高的情况下，单一的`Buffer Pool`可能会影响请求的处理速度。所以在`Buffer Pool`特别大的时候，我们可以把它们拆分成若干个小的`Buffer Pool`，每个`Buffer Pool`都称为一个`实例`，它们都是独立的，独立的去申请内存空间，独立的管理各种链表，独立的等等，所以在多线程并发访问时并不会相互影响，从而提高并发处理能力。我们可以在服务器启动的时候通过设置`innodb_buffer_pool_instances`的值来修改`Buffer Pool`实例的个数

![image-20250525175943861](/assets/images/mysql/image-20250525175943861.png)

​    不过也不是说`Buffer Pool`实例创建的越多越好，分别管理各个`Buffer Pool`也是需要性能开销的，设计`InnoDB`的大佬们规定：当innodb_buffer_pool_size的值小于1G的时候设置多个实例是无效的，InnoDB会默认把innodb_buffer_pool_instances 的值修改为1。而我们鼓励在`Buffer Pool`大小或等于1G的时候设置多个`Buffer Pool`实例。

## Change Buffer

<u>*首先要明确的一点是，他是干嘛的？*</u>

在更新数据的时候，如果该数据有**非唯一**二级索引，那么更新数据之后，还要去更新对应的二级索引，在大量写入的时候，这部分（更新二级索引的开销）就是影响性能的一个因素

所以要对这个部分进行优化



<u>*如果是唯一的二级索引，也不用优化，Why？*</u>

因为对于**唯一索引**，当你插入或修改数据时，数据库**必须立即去检查**这个值是否已经存在，以保证其唯一性。这个检查过程本身就需要从磁盘读取索引页，所以也就无法使用 Change Buffer 来“延迟”这个操作了。既然反正都要读磁盘（就顺便改了），就没必要再用 Change Buffer 了。



一句话解释： 对**非唯一二级索引，且不在内存时**进行更新操作时，为了减少磁盘IO，而先将更新操作记录在change buffer里（在buffer pool里），等后续merge（再次访问该数据页，或者定期merge）的时候才是真正修改数据的时候，适用于写多读少的情况



**什么条件下可以使用 change buffer 呢？**

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。



**为什么唯一索引不适用changebuffer？**

```sql
-- 场景演示：唯一索引为什么不能用Change Buffer

-- 表结构
CREATE TABLE users (
    id INT PRIMARY KEY,
    email VARCHAR(100) UNIQUE,  -- 唯一索引
    status INT,                 -- 非唯一索引
    INDEX idx_status(status)
);

-- 当插入数据时
INSERT INTO users VALUES (1, 'test@email.com', 1);

-- 对于唯一索引email：
-- MySQL必须立即检查 'test@email.com' 是否已存在
-- 这就要求必须读取索引页到内存进行判断
-- 既然已经读取了页，就没必要用Change Buffer了

-- 对于非唯一索引status：
-- 不需要检查，可以直接记录"要插入status=1"这个操作
-- 延迟到后面再真正插入

```



<u>***Merge 操作是什么？***</u>

简单来说，**Merge 操作就是将记录在 Change Buffer 中的“修改日志”应用到真实的二级索引页（Disk Page）上的过程。**



<u>***Merge 操作在什么时候会被触发？***</u>

这正是 `Change Buffer` 设计的精髓所在。它并不会在你一提交 `INSERT` 语句后就立即执行，而是选择在以下几个时机进行，以达到最优性能：

1. **当二级索引页被访问时（最重要的时机）**
   - 当一个 `SELECT` 查询需要用到这个二级索引时（比如 `WHERE` 条件走了这个索引），系统必须去读取对应的索引页。
   - 在从磁盘读取这个页面后，InnoDB 会检查 `Change Buffer`，看看这个页面有没有“待办”的修改。
   - 如果发现有，就会**立即触发 Merge 操作**，将 `Change Buffer` 中的变更应用到刚读入内存的页面上，然后再执行查询。
   - **这样做是为了保证数据的一致性**，确保查询能读到最新的、正确的数据。
2. **后台 Master Thread 定期合并**
   - InnoDB 有一个后台的主线程（Master Thread），它会周期性地检查 `Change Buffer`。
   - 当数据库系统比较空闲（I/O 负载不高）时，这个线程就会主动进行 Merge 操作，将 `Change Buffer` 中的修改慢慢地、持续地应用到磁盘上，从而避免 `Change Buffer` 占用过多内存，也减轻了未来访问时的合并压力。
3. **数据库正常关闭时**
   - 当你执行一个正常的数据库关闭命令时，为了确保所有数据都完整地保存到磁盘上，InnoDB 会执行一次完整的 Merge 操作，清空 `Change Buffer` 中所有的变更记录。
4. **数据库做 Checkpoint（检查点）时**
   - 当 Redo Log（重做日志）快要写满，触发 Checkpoint 操作时，也可能会伴随着一部分 Merge 操作，将相关的脏页刷写到磁盘。





**使用场景**

因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

## **详解 Doublewrite Buffer**

### **1. 核心概念：它到底解决了什么问题？**

它只为了解决一个问题：**防止部分页写入（Partial Page Write）**。

- **背景**：InnoDB 从内存（Buffer Pool）向磁盘写数据，是以“页（Page）”为单位的，通常一页是 16KB。但是，操作系统的文件系统写入数据并非原子的，它可能是以更小的单位（如 4KB）来写的。
- **极端情况**：想象一下，当 InnoDB 正在把一个 16KB 的脏页写入磁盘时，刚写了 8KB，服务器突然断电了。
- **后果**：此时，磁盘上的这个数据页就**彻底损坏**了。它既不是更新前的旧数据，也不是更新后的新数据，而是一个“半成品”的垃圾数据。这种损坏是**物理性**的，它的校验和（checksum）会失败，内部数据结构也可能完全错乱。
- **为什么 Redo Log 无能为力**：如前所述，当 InnoDB 重启进行崩溃恢复时，它会尝试用 Redo Log 来恢复数据。但当它发现那个数据页是个物理损坏的“半成品”时，Redo Log 里的操作指令就失去了应用的基准，恢复会失败，导致数据永久性损坏或丢失。

**Doublewrite Buffer 就是为了防止这种情况发生而设立的“双保险”。**

### **2. Doublewrite Buffer 的工作流程**

Doublewrite Buffer 由两部分组成：

1. **内存中的 Doublewrite Buffer**：在 InnoDB Buffer Pool 中的一块连续内存区域（大小通常为 2MB）。
2. **磁盘上的 Doublewrite Buffer**：在系统表空间（ibdata 文件）或者独立文件中，是一块连续的磁盘空间。

它的工作流程（刷脏页时）分为两步“写”：

**第一步：第一次写 (Write to Doublewrite Buffer on Disk)**

1. 当 InnoDB 需要将一批脏页（例如100个页面）刷入磁盘时，它**不会**直接把这些脏页写到它们各自的数据文件（`.ibd` 文件）中。
2. 相反，它会先把这100个脏页**完整地、原封不动地复制**到**内存中的 Doublewrite Buffer**。
3. 然后，调用一次 `fsync()`，将**内存中的 Doublewrite Buffer** 的内容，以一个**大的、连续的 I/O 操作**，一次性地写入到**磁盘上的 Doublewrite Buffer** 存储区。
   - **关键点**：这是一个**顺序写（Sequential Write）**操作。因为是连续写入一大块数据，所以速度很快，并且中途发生断电导致写入失败的概率远低于多次离散写入。

**第二步：第二次写 (Write to Final Data Files)**

1. 当上面的第一次写**成功完成**后，InnoDB 才开始执行第二次写操作。
2. 它会把**内存中的 Doublewrite Buffer**（或者直接从 Buffer Pool 中对应的脏页）里的数据页，逐个写入到它们最终应该在的表数据文件（`.ibd` 文件）中。
   - **关键点**：这是一个**随机写（Random Write）操作。因为这些脏页可能属于不同的表、不同的索引，在磁盘上的位置是离散的。“部分页写入”的风险主要就发生在这里。**

### 3. 崩溃恢复时如何工作？

现在，我们来看它如何在崩溃后发挥作用：

1. **数据库重启后，InnoDB 开始进行恢复**。
2. 它会检查一个数据页的完整性（通过校验和等机制）。
3. **情况A：数据页是完好的。**
   - 这说明在第二次写的过程中没有发生意外。接下来就轮到 Redo Log 出场了，InnoDB 会用 Redo Log 里的记录来检查这个页面是否需要更新，并把它恢复到断电前的最终状态。
4. **情况B：数据页被检测为“损坏”（Partial Page Write 发生）！**
   - 这时，Redo Log 已经无能为力了。
   - **Doublewrite Buffer 登场救场！** InnoDB 会去**磁盘上的 Doublewrite Buffer** 区域中，找到这个损坏页在崩溃前的一个**完整、正确的副本**。
   - 然后，用这个副本**覆盖**掉数据文件中那个已经损坏的页，相当于做了一次“**物理恢复**”。
   - 物理恢复完成后，磁盘上的这个页就变成了一个**一致且完整**的旧版本。
   - 最后，再应用 Redo Log，把这个恢复好的旧版本页面更新到最新的状态。

### 4. 总结：Redo Log vs. Doublewrite Buffer

| 特性           | Doublewrite Buffer (双写缓冲)                  | Redo Log (重做日志)                                      |
| -------------- | ---------------------------------------------- | -------------------------------------------------------- |
| **解决问题**   | **物理**数据页损坏 (Partial Page Write)        | **逻辑**数据丢失 (已提交事务的修改)                      |
| **保护对象**   | 保护数据页的**完整性**，是Redo Log能工作的前提 | 保护已提交事务的**持久性** (ACID中的D)                   |
| **记录内容**   | 数据页的**完整物理副本**                       | 对页面进行的**增量修改操作** (比如：在X页的Y偏移量写入Z) |
| **写入方式**   | 刷脏页时批量写入，包含一次大的顺序写           | 事务提交时写入，是小的、频繁的顺序写                     |
| **一句话总结** | **数据页的“备份副本”**，防止页损坏             | **数据库操作的“账本”**，用于重做操作                     |

性能影响：

虽然名字叫"双写"，会带来一定的 I/O 开销，但由于它的第一次写是高效的顺序写，并且它极大地保障了数据的安全性，因此在绝大多数场景下，这个开销是完全值得的。只有在一些支持原子写入的特殊硬件（如 Fusion-io 卡）上，才有可能考虑关闭它。

## ⚙️ InnoDB 性能调优核心参数

面试中经常会被问到："你做过哪些 MySQL 性能调优？" 以下参数是最常被提及的调优点。

### Buffer Pool 相关

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `innodb_buffer_pool_size` | 128M | 服务器物理内存的 **50-70%** | InnoDB 最重要的参数，缓存数据和索引 |
| `innodb_buffer_pool_instances` | 1 | 8-16（当 buffer_pool_size ≥ 1G 时） | 减少 Buffer Pool 的竞争，提高并发 |

```sql
-- 示例：16GB 内存服务器
SET GLOBAL innodb_buffer_pool_size = 10737418240; -- 10GB
SET GLOBAL innodb_buffer_pool_instances = 8;
```

**面试要点**：
- Buffer Pool 越大，磁盘 I/O 越少，但不是越大越好（要给操作系统留内存）
- 多实例适用于高并发场景，可以减少线程竞争

---

### Redo Log 相关

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `innodb_flush_log_at_trx_commit` | 1 | **1**（生产环境） | 控制事务提交时 Redo Log 的刷盘策略 |
| `innodb_log_file_size` | 48M | 256M-2G | 单个 Redo Log 文件大小 |
| `innodb_log_files_in_group` | 2 | 2-3 | Redo Log 文件组数量 |

**`innodb_flush_log_at_trx_commit` 参数详解（面试必问）：**

| 值 | 含义 | 性能 | 安全性 |
|----|------|------|--------|
| 0 | 每秒写入并刷盘一次 | ⭐⭐⭐⭐⭐ | ⭐（崩溃丢失 1 秒数据） |
| 1 | 每次事务提交都刷盘 | ⭐⭐ | ⭐⭐⭐⭐⭐（最安全） |
| 2 | 每次事务提交写入，每秒刷盘 | ⭐⭐⭐⭐ | ⭐⭐⭐（操作系统崩溃可能丢失数据） |

```sql
-- 生产环境推荐配置
SET GLOBAL innodb_flush_log_at_trx_commit = 1;
SET GLOBAL innodb_log_file_size = 536870912; -- 512MB
```

**面试要点**：
- 这个参数直接权衡性能和数据安全
- 默认值 1 是最安全的，但性能最低
- **重要**：这个参数和 `sync_binlog` 要配合设置（见下方）

---

### Binlog 相关

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `sync_binlog` | 1 | **1**（生产环境） | 控制 Binlog 的刷盘频率 |
| `binlog_format` | ROW | **ROW** | Binlog 记录格式 |
| `binlog_cache_size` | 32K | 1M-4M | Binlog 缓存大小 |

**`sync_binlog` 参数详解：**

| 值 | 含义 |
|----|------|
| 0 | 不同步，由操作系统决定何时刷盘 |
| N | 每 N 个事务才刷盘一次 |
| 1 | 每个事务提交都刷盘（最安全） |

**`binlog_format` 参数详解：**

| 值 | 优点 | 缺点 | 适用场景 |
|----|------|------|----------|
| STATEMENT | 文件小、节省空间 | 可能导致主从不一致 | 简单业务 |
| ROW | 数据一致性最好 | 文件大、可能有 binlog 占用过多问题 | **生产环境推荐** |
| MIXED | 自动选择 | 调试困难 | 通用场景 |

**经典面试题：双 1 配置**

```sql
-- 生产环境的"双 1"配置（最安全）
SET GLOBAL innodb_flush_log_at_trx_commit = 1;
SET GLOBAL sync_binlog = 1;
```

**含义**：
- `innodb_flush_log_at_trx_commit = 1`：每次事务提交，Redo Log 都持久化到磁盘
- `sync_binlog = 1`：每次事务提交，Binlog 都持久化到磁盘

这是**最安全**的配置，保证了两阶段提交的一致性，但性能也是最低的。如果业务能容忍少量数据丢失，可以调整为：
- `innodb_flush_log_at_trx_commit = 2` 和 `sync_binlog = 10`（每 10 个事务刷一次）

---

### Change Buffer 相关

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `innodb_change_buffer_max_size` | 25 | 25-50 | Change Buffer 最大占 Buffer Pool 的百分比 |

**面试要点**：
- 写多读少的业务（如日志、账单系统）可以调大这个值（如 50）
- 读多写少的业务可以调小这个值（如 5-10），节省 Buffer Pool 空间

---

### Doublewrite Buffer 相关

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `innodb_doublewrite` | ON | **ON** | 是否开启双写缓冲 |
| `innodb_doublewrite_files` | 2 | 2 | 双写缓冲文件数量 |

**面试要点**：
- 普通服务器**不要关闭** Doublewrite Buffer，它防止部分页写入
- 只有在支持原子写入的硬件（如 Fusion-io 卡）上才考虑关闭

---

### 锁相关

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `innodb_lock_wait_timeout` | 50 | 10-50 | 行锁等待超时时间（秒） |
| `innodb_deadlock_detect` | ON | **ON** | 是否开启死锁检测 |

**面试要点**：
- `innodb_lock_wait_timeout` 设置太小会导致很多锁超时错误，太大会导致长时间等待
- 如果业务并发量特别高且死锁频繁，可以临时关闭死锁检测（`OFF`），依靠 `innodb_lock_wait_timeout` 来回滚事务

---

### 其他核心参数

| 参数 | 默认值 | 推荐值 | 说明 |
|------|--------|--------|------|
| `innodb_io_capacity` | 200 | **SSD: 2000-5000**<br>**HDD: 200-500** | InnoDB I/O 容量限制 |
| `innodb_io_capacity_max` | 2000 | **SSD: 4000-10000**<br>**HDD: 400-1000** | InnoDB 最大 I/O 容量 |
| `innodb_old_blocks_time` | 1000 | 1000 | 旧数据页从 LRU 的 old 区域移动到 young 区域的间隔时间（毫秒） |
| `innodb_read_only` | OFF | - | 只读模式（用于从库） |
| `max_connections` | 151 | 500-2000 | 最大连接数 |

**`innodb_io_capacity` 面试要点：**
- 这个参数控制 InnoDB 后台刷脏页的速度
- 设置过小：脏页堆积，磁盘 I/O 成为瓶颈
- 设置过大：磁盘 I/O 被打满，影响用户查询
- **推荐**：SSD 设置为 2000-5000，机械硬盘设置为 200-500

**`innodb_old_blocks_time` 面试要点：**
- 防止全表扫描把热数据挤出 Buffer Pool
- 默认 1000ms 意味着：加载到 Buffer Pool 的页在 1 秒内被多次访问才会被移到 young 区域
- 全表扫描的页通常只访问一次，会留在 old 区域，很快被淘汰

---

### 快速调优速查表

```sql
-- 🚀 生产环境推荐配置（16GB 内存服务器）

-- Buffer Pool
SET GLOBAL innodb_buffer_pool_size = 10737418240; -- 10GB
SET GLOBAL innodb_buffer_pool_instances = 8;

-- 日志安全（双 1 配置）
SET GLOBAL innodb_flush_log_at_trx_commit = 1;
SET GLOBAL sync_binlog = 1;

-- I/O 容量（SSD 服务器）
SET GLOBAL innodb_io_capacity = 3000;
SET GLOBAL innodb_io_capacity_max = 6000;

-- 连接数
SET GLOBAL max_connections = 1000;
SET GLOBAL innodb_lock_wait_timeout = 30;

-- Change Buffer（写多业务）
SET GLOBAL innodb_change_buffer_max_size = 40;
```

---

## 事务

### 事务AICD四个特性

- 原子性（Atomicity）：要么全做，要么全不做 **通过 Undo Log 保证**
- 隔离性（Isolation）：其它的状态转换不会影响到本次状态转换 **锁 + MVCC机制保证**
- 一致性（Consistency）：最后的结果符合所有现实世界中的约束 **由原子性、持久性、隔离性共同保障**
- 持久性（Durability）：该转换对应的数据库操作所修改的数据都应该在磁盘上保留下来 **通过Redo Log 和 WSL 保证**

详细解释：[【面试官来袭】第三弹之MySQL原理篇](https://mp.weixin.qq.com/s?__biz=Mzg5ODU2ODczMQ==&mid=2247487888&idx=1&sn=973635eeaf7d1916e62bbceda72d27bd&chksm=c061d6e4f7165ff271ee4bfc71de630c6538802b1d49c747bc0eb0be9264ae7619ed0648c47c#rd)

### 显示/隐式事务

- 一些复制语句
- 一些加载语句
- 等等

### 事务隔离级别（标准情况下）

- 读未提交：未提交的数据也对其他事物可见
  - 会发生脏读、不可重复读、幻读现象
- 读已提交：提交的数据才对其他事物可见
  - 会发生不可重复读、幻读（解决了脏读）
- 可重复读：一个事务执行过程中看到的数据和该事务**开始时始终保持一致**
  - 会发生幻读（解决了脏读、不可重复读）【在innodb的实现下也解决了大部分情况下的幻读现象，**但没有完全解决**】
- 串行化：会对记录加上读写锁，正在有多个事务同时对一条记录进行读写操作时，发生冲突时必须一个一个来执行
  - 没问题了（解决了脏读、不可重复读、幻读）

### 四个隔离级别分别用什么技术实现？

在深入每个级别之前，必须先理解 MVCC。这是 InnoDB 实现**读已提交 (RC)** 和**可重复读 (RR)** 这两个级别“读写不阻塞”的关键。

- **工作原理**：当修改一行数据时，InnoDB 不会直接覆盖旧数据，而是将旧数据存入一个叫做 **Undo Log** 的地方，并通过一个“版本链”将不同版本的数据串起来。
- **关键组件**：
  - **版本链**：一行数据的历史版本集合。
  - **Read View (读视图)**：当一个事务开始时，它会创建一个“快照”（Read View）。这个快照记录了当前所有活跃（未提交）的事务 ID。事务在读取数据时，会沿着版本链去寻找一个**对当前快照可见**的版本。



> #### 1. Read Uncommitted (读未提交)
>
> - **实现技术**：基本不加锁（仅在写操作时加必要的锁）。
> - **简要介绍**：这是最简单的级别。在 `SELECT` 数据时，它**不使用 MVCC**，而是直接读取数据行最新的、内存中的版本，无论修改它的事务是否已提交。因此，它速度最快，但隔离性最差，会产生脏读。
>
> #### 2. Read Committed (读已提交)
>
> - **实现技术**：**MVCC**。
> - **简要介绍**：这是很多数据库（如 Oracle, PostgreSQL）的默认级别。它的核心在于**“每一次 `SELECT` 都会创建一个新的 Read View”**。
>   - 当你的事务中第一次 `SELECT` 时，它会创建一个 Read View，读取符合这个视图的数据。
>   - 当另一个事务提交了更新后，你的事务中第二次 `SELECT`，它会**重新创建一个新的 Read View**。这个新的视图就能看到那个已提交事务的修改了。
>   - **结果**：这就导致了在一个事务内，两次相同的查询结果可能不同，即“不可重复读”。
>
> #### 3. Repeatable Read (可重复读) 【InnoDB 默认】
>
> - **实现技术**：**MVCC + Next-Key Lock (临键锁)**。
> - **简要介绍**：这是 InnoDB 的默认级别，实现得非常精妙。
>   - **解决不可重复读 (靠 MVCC)**：**与 RC 的关键区别**在于，RR 级别的事务**只在事务开始时的第一个 `SELECT` 语句时创建一个 Read View**，并且在整个事务期间都**复用**这同一个 Read View。无论其他事务如何提交，当前事务看到的始终是它刚开始时那个“快照”中的数据，从而保证了“可重复读”。
>   - **解决幻读 (靠 Next-Key Lock)**：您提到的“解决了大部分情况下的幻读”就是靠这个。当事务进行范围查询或更新操作（如 `UPDATE ... WHERE id > 10`）时，InnoDB 不仅会锁住满足条件的行（Record Lock），还会锁住这些行之间的“**间隙**”（Gap Lock）。这种“行锁+间隙锁”的组合就是 **Next-Key Lock**。它阻止了其他事务在这个范围内插入新的数据，从而避免了幻读。
>
> #### 4. Serializable (串行化)
>
> - **实现技术**：**锁**。
> - **简要介绍**：这是最严格的级别。它的实现非常直接：
>   - 它会在 RR 级别的基础上，**自动地将所有普通的 `SELECT` 语句升级为 `SELECT ... LOCK IN SHARE MODE`**。
>   - 这意味着，一个事务在读取数据时，就会给这些数据加上**读锁（共享锁）**。其他事务如果想修改这些数据，就必须等待读锁被释放。
>   - **结果**：读会阻塞写，写也会阻塞读。所有事务对同一数据的访问都变成了串行执行，完全避免了所有并发问题，但性能也最差。

### MVCC

#### 1、快照读和当前读

##### 快照读

快照读又叫一致性读，读取的是快照数据。不加锁的简单的 `SELECT `都属于快照读，即不加锁的非阻塞读;

比如这样:

```mysql
SELECT *FROM player WHERE
```

之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于MVCC，它在很多情况下，避免了加锁操作，降低了开销。
既然是基于多版本，那么快照读可能读到的并**不一定是**数据的**最新版本**，而有可能是之前的历史版本。
快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读。

##### 当前读

读的就是最新的版本



#### 2、Read View

![image-20250625110202110](/assets/images/mysql/image-20250625110202110.png)

![image-20250625110225879](/assets/images/mysql/image-20250625110225879.png)

> 理解一下：
>
> 在开始创建rearview的同时，会记录一个列表m_ids[]，里面存的是当前活跃事物的id
>
> 然后找出`该列表中的最小值`和`全局事物最大事物id+1`作为最大值，作为高低水位
>
> 如果当前数据版本对应的事物id小于低水位，则代表这个事物必然已提交（因为事物就两种状态，已提交或者未提交，在创建事物时已经保存了当前活跃（未提交）事物的id，所以这种情况下只能对应另一种情况--已提交）1⃣️
>
> 如果当前数据事物id大于高水位，则代表该版本是当前事物创建之后的事物修改的，`不可见`
>
> 最后一种情况：低水位 < 当前数据的事物id < 高水位 :
>
> 
>
> - 若当前数据的事物id在活跃列表中，则代表还未提交，`不可见`
> - 若不在，就代表已提交（和1⃣️的原理一样）， `可见`

**最后一种情况为什么那样划分？**
举个例子：当前共有10个全局事物：[1,2,3,    4     ,5,6,    7,8    ,9,10]

假设创建rearview时活跃列表为[4, 7, 8]

那低水位就是4， 高水位就是11

那对应第三种情况，不在活跃列表里的事物id有可能是5， 6， 9， 10，因为他们不在活跃列表里所以只能是已提交

**总结一句话就是，活跃列表里记的是未提交的，除此之外的事物id都是已提交的**



按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。

因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。

当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。

在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。

数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。

这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。

详细可以看这篇文章：[MVCC?][https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/MySQL%e5%ae%9e%e6%88%9845%e8%ae%b2/08%20%20%e4%ba%8b%e5%8a%a1%e5%88%b0%e5%ba%95%e6%98%af%e9%9a%94%e7%a6%bb%e7%9a%84%e8%bf%98%e6%98%af%e4%b8%8d%e9%9a%94%e7%a6%bb%e7%9a%84%ef%bc%9f.md]

---

## 索引

联合索引失效时，范围查找的情况，需要分为 > 和 >= 也就是不带等号和带等号的两种情况（涉及到优化器的选择方式）

### 索引扫描方式的区别

> ### 1. `>` 或 `<` (不含等号)
> - 使用 **开区间扫描**
> - 索引优化器认为范围的边界值不确定性更大
> - 为了避免过多的随机IO，会**截断**联合索引的使用
> - 只使用联合索引的前面部分字段
>
> ### 2. `>=` 或 `<=` (包含等号)  
> - 使用 **闭区间扫描**
> - 包含了精确的边界值匹配
> - 索引优化器认为可以更好地利用索引的有序性
> - 可以继续使用联合索引的后续字段
>
> ## 具体原理
>
> 假设有联合索引 `(age, status)`：
>
> ```sql
> -- 不走完整索引 (key_len=49)
> WHERE age > 25 AND status = 'active'
> 
> -- 走完整索引 (key_len=54) 
> WHERE age >= 25 AND status = 'active'
> ```
>
> **原因分析：**
>
> 1. **`age > 25`**: 需要跳过所有 `age = 25` 的记录，边界不明确
> 2. **`age >= 25`**: 包含 `age = 25` 的记录，可以精确定位起始位置
>
> ## MySQL优化器的考量
>
> - **成本评估**: `>=` 操作可以更好地预估扫描范围
> - **索引有序性**: 闭区间查询能更充分利用B+树的有序特性  
> - **回表成本**: 开区间查询可能导致更多不必要的回表操作
>
> 这是MySQL查询优化器基于统计信息和成本模型做出的优化决策，目的是在不同场景下选择最优的执行计划。

## 锁

### 3.1 全局锁

​    全局锁执行后整个数据库就是只读状态，主要用于做全库备份，但会造成业务停滞，因为加全局锁后数据库不可用了

​    Innodb引擎中，由于有MVCC支持，所以在进行全库备份时候可以使用可重复读的隔离级别，使用ReadView，在这种隔离级别下，整个事务都会使用一开始的read view，别的不影响

​    MyISAM不支持事务，所以要使用全局锁做备份

### 3.2 表级锁

我会按照每个锁的**“角色定位”**来重新组织，并解释清楚它们各自“为什么存在”。

---

首先要明确，虽然 InnoDB 引擎以其高效的**行级锁**闻名，但在某些特定场景下，**表级锁**依然扮演着不可或缺的角色。它们的目的各不相同，有的是为了保护表结构，有的是为了协调不同锁的类型，有的是为了实现特定功能。

------

#### 1. 元数据锁 (Metadata Lock, MDL) - “结构守护者”

这是最重要的、也是最容易引发“雪崩”问题的锁。

- **核心目的 (Why):** 保护表的**结构（元数据）**，而不是表里的数据。它的存在是为了保证事务在执行期间，表的定义不会被其他会话修改。

  想象一下，如果你的事务正在查询一张表（`SELECT * FROM users`），执行到一半时，另一个会话突然把这张表的一个字段给删了（`ALTER TABLE users DROP COLUMN age`），那结果将是灾难性的。MDL 锁就是为了防止这种事情发生。

- **工作方式 (How):**

  - **自动加锁**：你不需要手动操作，只要你对一个表执行任何 SQL 语句（包括最简单的 `SELECT`），MySQL 就会自动为你加上 MDL 锁。
  - **事务级生命周期**：MDL 锁会一直持有，直到你的**事务提交或回滚**后才会释放。
  - **锁的类型**：分为读锁（`MDL_SHARED`）和写锁（`MDL_EXCLUSIVE`）。
    - 你对表做 CRUD 操作时，加的是**MDL 读锁**。
    - 你对表做 DDL 操作时（如`ALTER TABLE`），加的是**MDL 写锁**。

- **兼容性与著名问题 (The Problem):**

  - **读读不冲突**：多个事务可以同时持有 MDL 读锁，一起对表进行 CRUD。
  - **读写冲突，写写冲突**：只要有一个事务想获取 MDL 写锁，它就必须等待所有持有 MDL 读锁的事务结束。反之亦然。

  **经典“堵塞”场景（你笔记中提到的）：**

  1. **会话 A**：开启一个长事务，并查询了 `users` 表（获取了 MDL 读锁，且不释放）。
  2. **会话 B**：想给 `users` 表增加一个字段，执行 `ALTER TABLE`（尝试获取 MDL 写锁，但因为 A 的存在而被阻塞）。
  3. **会话 C, D, E...**：此时发来新的 `SELECT` 请求（尝试获取 MDL 读锁）。
  4. **结果**：因为 MySQL 的锁队列中，写锁（会话 B）的优先级高于读锁，所以所有后续的读锁请求（C, D, E）都会被排在 B 的后面，全部被阻塞。**最终，一个未提交的长事务就可能因为一个 DDL 操作，而“冻结”整个表的所有访问。**

------

#### 2. 意向锁 (Intention Lock, IS/IX) - “门卫/信号灯”

这是最容易被误解，但设计得非常巧妙的锁。它**不是用来锁数据的**，而是用来**“发信号”**的。

- **核心目的 (Why):** **快速判断表里是否有行锁存在，从而避免全表扫描。** 它的存在是为了协调**表锁**和**行锁**之间的冲突。

  **问题场景：**

  - 事务 A 给表 `users` 中的某一行加了行锁（比如 `SELECT ... FOR UPDATE`）。
  - 事务 B 这时想给整个 `users` 表加上一个表锁（`LOCK TABLES users WRITE`）。
  - 为了加上这个表锁，事务 B **必须**确保表里没有任何一行被其他事务锁住。那么，事务 B 要如何检查呢？难道要把表里的**每一行**都扫一遍吗？如果表有上亿行，这显然是不可接受的。

  **解决方案：**

  - InnoDB 规定，当你想给某一行加行锁（共享锁S 或 独占锁X）之前，**必须先在表级别加上一个对应类型的意向锁**。
    - 加**行共享锁 (S)** 前 -> 先加**意向共享锁 (IS)**
    - 加**行独占锁 (X)** 前 -> 先加**意向独占锁 (IX)**

  现在，当事务 B 想加表锁时，它**只需要检查表上有没有意向锁**就行了。如果发现表上存在意向锁，就说明“里面有人（行锁）”，B 必须等待。这个检查速度是 O(1) 的，非常快。

- **兼容性 (How):**

  - **意向锁之间不冲突**：多个事务可以同时持有 IS 或 IX 锁，因为它们只是标记“我有意向要锁某几行”，但具体是哪几行，它们自己不关心，也不会冲突。
  - **意向锁与行锁不冲突**：这是理所当然的，意向锁就是为了支持行锁而存在的。
  - **意向锁与表锁冲突**：
    - 事务想加**表共享锁（`LOCK TABLES ... READ`）**，必须等待所有 **IX** 锁释放。
    - 事务想加**表独占锁（`LOCK TABLES ... WRITE`）**，必须等待所有 **IS 和 IX** 锁释放。

------

#### 3. 表锁 (Table Lock) - “终极武器”

这是最传统、最粗暴的锁，一般在 InnoDB 中我们应该**尽量避免**手动使用它。

- **核心目的 (Why):** 在某些特殊场景下，完全锁定整张表，禁止其他会话进行指定类型的操作。例如，进行不涉及事务的批量数据迁移。
- **工作方式 (How):**
  - 通过 `LOCK TABLES table_name [READ | WRITE]` 显式使用。
  - **读锁 (READ)**：持有该锁的会话可以读表，其他会话也可以**读**，但任何会话（包括持有者自己）都不能**写**。
  - **写锁 (WRITE)**：持有该锁的会话可以对表进行读写，但其他任何会话都**不能进行任何读写**操作。
  - **重要副作用**：你的笔记中提到了，一个会话通过 `LOCK TABLES` 锁住一张表后，在解锁（`UNLOCK TABLES`）之前，通常不能再访问其他表（除了某些特殊情况）。

------

#### 4. AUTO_INC 锁 - “号码分配器”

这是一个非常特殊的表级锁，只为了一个目的服务。

- **核心目的 (Why):** 在并发插入时，保证 `AUTO_INCREMENT` 自增列的值是**唯一且连续递增**的。
- **工作方式 (How):**
  - 它是一种**短时持有**的表锁。一个事务在插入数据需要获取自增值时，会持有这个 AUTO_INC 锁，获取并分配完 ID 后，**立即释放**，而不需要等到事务结束。
  - **模式演进**：由于这个表锁在高并发下会成为瓶颈，MySQL 引入了 `innodb_autoinc_lock_mode` 参数来优化它。
    - **`mode=1` (consecutive, 默认)**：对于简单的 `INSERT`，使用更轻量的互斥量（mutex）来分配 ID，性能更高。对于 `INSERT ... SELECT` 这样的批量插入，才会升级为传统的 AUTO_INC 表锁，以保证分配的 ID 块是连续的。
    - **`mode=2` (interleaved)**：完全放弃表锁，所有插入都使用互斥量。并发性能最好，但**不保证**批量插入的 ID 是连续的（它们只会是唯一且递增的）。

**总结与梳理**

| 锁类型                | 角色定位    | 目的                                 | 触发方式           | 生命周期         |
| --------------------- | ----------- | ------------------------------------ | ------------------ | ---------------- |
| **元数据锁 (MDL)**    | 结构守护者  | 防止在事务执行期间，表结构被修改     | 任何 SQL 操作      | 事务级           |
| **意向锁 (IS/IX)**    | 门卫/信号灯 | 协调表锁与行锁，快速判断表内有无行锁 | DML 操作加行锁之前 | 事务级           |
| **表锁 (Table Lock)** | 终极武器    | 手动锁定整张表，进行特殊操作         | `LOCK TABLES`      | 手动加锁/解锁    |
| **AUTO_INC 锁**       | 号码分配器  | 保证自增 ID 的正确分配               | 插入含自增列的行   | 语句级（非常短） |

这样梳理下来，每个锁的“人设”和“职责”就非常清晰了。它们在不同的层面，共同保障了 InnoDB 的数据一致性、完整性和并发性能。

### 3.3 行级锁

行级锁的类型主要有三类:

- Record Lock，记录锁，也就是仅仅把一条记录锁上;
- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身
- Next-Key Lock:Record Lock+ Gap Lock 的组合，锁定一个范围，并且锁定记录本身。

#### Record Lock（记录锁）

锁住的是一条记录，记录锁是有S锁（共享锁）和X锁（独占锁）之分的。

当事务执行Commit后，事务中生成的锁都会释放、

#### Gap Lock（间隙锁）

该锁只存在于可重复读隔离级别，目的是为了解决可重复读级别下的**幻读**现象

间隙锁虽然存在X型间隙锁和S型间隙锁，但是并没有什么区别，间隙锁之间是**兼容**的

即**两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系**，因为间隙锁的目的是防止插入幻影记录而提出的。

#### Next-Key Lock（临键锁）

是Record Lock + Gap Lock的组合，锁定一个范围，并锁定记录本身。

![image-20250528131019038](/assets/images/mysql/image-20250528131019038.png)

​    next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了X型的 next-key lock，那么另外一个事务在获取相同范围的X型的 next-key lock 时，是会被阻塞的。
​    比如，一个事务持有了范围为(1,10]的X型的 next-key lock，那么另外一个事务在获取相同范围的X型的 next-key lock 时，就会被阻塞。
​    虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑X型与S型关系，X型的记录锁与X型的记录锁是冲突的。

#### 插入意向锁

​    一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁(next-key lock 也包含间隙锁)
如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止(释放间隙锁的时刻)

在此期间会生成一个`插入意向锁`，表明有事务想在某个区间插入新记录，但是现在处于等待状态。





​    插入意向锁名字虽然有意向锁，但是它并**不是意向锁，它是一种特殊的间隙锁，属于行级别锁**
​    如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。
​    插入意向锁与间隙锁的另一个非常重要的差别是:尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁(当然，插入意向锁如果不在间隙锁区间内则是可以的)。



<u>*以下为AI总结，个人感觉总结的无敌*</u>

> 你的笔记已经非常准确了，我们要做的是把这些知识点用一条清晰的逻辑线串联起来，并用更生动的例子来加深理解。
>
> ------
>
> ### **InnoDB 行级锁全解析**
>
> 首先，要有一个顶层认知：InnoDB 之所以设计出如此复杂的行锁体系，根本目的只有一个——**在保证事务隔离性的前提下，实现最大程度的并发。**
>
> 在 MySQL 默认的**可重复读（Repeatable Read）**隔离级别下，为了解决**幻读（Phantom Read）**问题，才诞生了 Gap Lock 和 Next-Key Lock 这两个“大杀器”。
>
> 我们来逐一拆解这些“锁零件”，看看它们是如何协同工作的。
>
> ------
>
> #### 1. Record Lock (记录锁) - “精准点杀”
>
> 这是最容易理解的行锁，它的作用也最单纯。
>
> - **是什么**：一个**精准地锁定单条索引记录**的锁。注意，它锁的是**索引**，而不是数据行本身。如果你的表没有设置任何索引，InnoDB 会创建一个隐藏的聚集索引，并使用它来加锁。
> - **为什么需要**：为了防止其他事务对**同一条记录**进行并发的修改或删除，保证数据一致性。
> - **如何工作**：分为两种模式，与标准的锁定义一致。
>   - **共享锁 (S-Lock)**：`SELECT ... LOCK IN SHARE MODE;`。多个事务可以同时持有同一条记录的 S 锁，大家都能读，但谁都不能改。
>   - **独占锁 (X-Lock)**：`SELECT ... FOR UPDATE;` 或 `UPDATE`, `DELETE`。只有一个事务能持有 X 锁，该事务可以读写这条记录，其他任何事务都不能再对它加任何锁（S 或 X）。
> - **一句话总结**：锁住某一行，不让别人动。
>
> ------
>
> #### 2. Gap Lock (间隙锁) - “禁止入内”
>
> 这是 InnoDB 的一大特色，也是理解幻读的关键。
>
> - **是什么**：一个**锁定索引记录之间“间隙”**的锁。它不锁定任何已存在的记录，只锁定一个范围。这个范围可以是两条索引记录之间，也可以是第一条记录之前或最后一条记录之后的空间。
> - **为什么需要**：**它的唯一目的，就是在「可重复读」隔离级别下，防止其他事务在这个间隙中插入新的记录，从而避免幻读。**
> - **如何工作**：
>   - 比如一个索引有两条记录，值是 10 和 20。那么 Gap Lock 就可以锁定 `(10, 20)` 这个开区间。
>   - **核心特性（你的笔记提到了，非常关键）**：**间隙锁之间是互相兼容的**。一个事务持有了 `(10, 20)` 的间隙锁，另一个事务**也**可以持有 `(10, 20)` 的间隙锁。
>   - **为什么兼容？** 因为 Gap Lock 的使命是**阻止插入**，而不是阻止其他事务也来“阻止插入”。大家的目标是一致的。就像两个保安都守着一个空车位，他们的任务都是不让新车停进来，他们俩之间并没有冲突。
> - **一句话总结**：锁住一个范围，不让新数据插进来。
>
> ------
>
> #### 3. Next-Key Lock (临键锁) - “标准套餐”
>
> 这是 InnoDB 在 RR 级别下，行锁的**默认实现**。它不是一个新东西，而是前面两种锁的组合。
>
> - **是什么**：**Record Lock + Gap Lock 的组合**。它既锁定一条索引记录本身，也锁定这条记录之前的那个间隙。用数学区间表示就是 **(previous_key, current_key]**，一个左开右闭的区间。
> - **为什么需要**：为了在锁定记录的同时，防止幻读的发生。这是 InnoDB 在性能和数据一致性之间做出的一个精妙平衡。
> - **如何工作**：
>   - **举例**：一个索引有 `10, 20, 30` 三条记录。
>   - 那么这张表实际上被分成了几个 Next-Key Lock 的潜在范围：`(-∞, 10]`, `(10, 20]`, `(20, 30]`, `(30, +∞]`。
>   - 当一个事务执行 `SELECT * FROM table WHERE id = 20 FOR UPDATE;` 时，它获取的就是 `(10, 20]` 这个区间的 Next-Key Lock。
>   - **这个锁的效果是**：
>     1. 在 `id=20` 这条记录上加了一个 **Record Lock (X锁)**。
>     2. 在 `(10, 20)` 这个间隙上加了一个 **Gap Lock**。
>   - **结果**：其他事务既不能修改 `id=20` 这条记录，也不能在 `10` 和 `20` 之间插入任何新纪录（比如 `id=15`），从而彻底杜绝了幻读。
> - **锁冲突**：你笔记中分析的非常对！两个事务如果想获取同一个 Next-Key Lock，会不会冲突，**取决于 Record Lock 部分**。因为 Gap Lock 彼此兼容，所以冲突的根源在于对同一条记录加了互不兼容的 Record Lock（比如两个 X 锁）。
>
> ------
>
> #### 4. Insertion Intention Lock (插入意向锁) - “排队等候”
>
> 这是在并发插入场景下，为了提升性能而设计的一种**特殊的间隙锁**。
>
> - **是什么**：当一个事务**想要**在一个被 Gap Lock 锁定的间隙中插入一条新记录时，它不能立刻插入，必须等待。在等待时，它会先在内存中生成一个锁结构，表明“我**有意向**要插入数据”，这个锁就是插入意向锁。
> - **为什么需要**：为了让多个**准备插入到同一间隙**但**值不冲突**的事务，可以不用互相等待。
> - **如何工作**：
>   - **场景**：事务 A 持有 `(10, 20)` 的 Gap Lock。
>   - 事务 B 想插入 `id=15`，事务 C 想插入 `id=16`。
>   - B 和 C 都会被 A 的 Gap Lock 阻塞。在等待时，B 会生成一个针对 `15` 的插入意向锁，C 会生成一个针对 `16` 的插入意向锁。
>   - **核心特性**：**插入意向锁之间互不冲突**。B 和 C 虽然都在等待，但它们之间没有矛盾。
>   - **一旦事务 A 提交**，释放了 Gap Lock，B 和 C 会同时接收到信号，然后继续完成插入。如果没有插入意向锁这个机制，B 和 C 可能还需要互相排队，并发性能就会下降。
> - **一句话总结**：在被间隙锁卡住时，表明“我想插队”的一种信号，多个不冲突的信号可以并存。
>
> ### **整体梳理与总结**
>
> | 锁类型                       | 角色定位     | 锁定目标             | 核心目的                                                 |
> | ---------------------------- | ------------ | -------------------- | -------------------------------------------------------- |
> | **Record Lock**              | **精准锁定** | 单条索引记录         | 保护单行数据，避免并发修改冲突。                         |
> | **Gap Lock**                 | **范围守护** | 索引记录之间的“空隙” | [RR级别] 防止幻读，禁止新纪录插入。                      |
> | **Next-Key Lock**            | **默认套餐** | 记录 + 前置间隙      | InnoDB在RR级别下默认的加锁方式，同时锁定数据并防止幻读。 |
> | **Insertion Intention Lock** | **插入信号** | 准备插入数据的位置   | 提高并发插入性能，表明插入意图，等待Gap Lock释放。       |
>
> 通过这套组合拳，InnoDB 在可重复读（Repeatable Read）隔离级别下，既实现了强大的并发控制，又通过 Next-Key Lock 机制顺便解决了幻读问题，使其几乎达到了串行化（Serializable）隔离级别的效果，但并发性能却要高得多。

### MySql是怎么加行级锁的

> [MySQL 是怎么加锁的？ | 小林coding](https://xiaolincoding.com/mysql/lock/how_to_lock.html#mysql-是怎么加行级锁的)



#### 唯一索引等值查询：



> - 存在：查到这条记录了，所以next-key lock退化成record lock
> - 没查到，就锁住第一条到第一条大于这条记录的记录，退化成gap lock，锁住这个间隙



#### 唯一索引范围查询：



> - 大于某个值（比如是 > 15）的情况
>
> <img src="/assets/images/mysql/image-20250807171737220.png" alt="image-20250807171737220" style="zoom:50%;" />
>
> - 大于等于某个值（比如 >= 15）的情况
>
> <img src="/assets/images/mysql/image-20250807171940957.png" alt="image-20250807171940957" style="zoom:40%;" />
>
> - 小于某个值，这个值不在表中（比如 < 6）
>
> <img src="/assets/images/mysql/image-20250807172211859.png" alt="image-20250807172211859" style="zoom:40%;" />
>
> - 小于等于某个值，这个值存在表中（比如 <= 5）
>
> <img src="/assets/images/mysql/image-20250807172529840.png" alt="image-20250807172529840" style="zoom:40%;" />
>
> <img src="/assets/images/mysql/image-20250807172815369.png" alt="image-20250807172815369" style="zoom:50%;" />
>
> 核心就是锁住已经扫描过的部分



#### 非唯一索引等值查询

| 场景           | 扫描行为                         | 二级索引锁                                 | 主键索引锁       |
| -------------- | -------------------------------- | ------------------------------------------ | ---------------- |
| 查询记录存在   | 扫描所有匹配记录直到第一个不匹配 | 匹配记录加 Next-Key 锁，不匹配记录加间隙锁 | 匹配记录加记录锁 |
| 查询记录不存在 | 扫描直到第一个不匹配记录         | 不匹配记录加间隙锁                         | 不加锁           |



> 当有一个事务持有二级索引的间隙锁 (22, 39) 时，什么情况下，可以让其他事务的插入 age = 22 或者 age = 39 记录的语句成功？又是什么情况下，插入 age = 22 或者 age = 39 记录时的语句会被阻塞？

这个问题的答案太多了，仔细看原帖

https://xiaolincoding.com/mysql/lock/how_to_lock.html#%E9%9D%9E%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%AD%89%E5%80%BC%E6%9F%A5%E8%AF%A2



<u>*以下为AI总结：*</u>

> 下面我将为你重新梳理 InnoDB 在 `REPEATABLE READ` 隔离级别下的加锁规则。我们将遵循一个清晰的逻辑路径：**从目标出发，理解默认行为，再看优化（退化）**。
>
> ------
>
> ### 一、核心原则：理解加锁的“初心”
>
> InnoDB 加锁的首要目标，是在默认的**可重复读 (Repeatable Read)** 隔离级别下，解决**幻读 (Phantom Read)** 问题。
>
> 1. 什么是幻读？
>
>    在一个事务内，先后两次执行同样的范围查询，第二次查询看到了第一次查询中没有的、由其他事务新插入的行。这些“幽灵般”多出来的行就是幻读。
>
> 2. 如何解决幻读？
>
>    必须阻止其他事务在你查询的范围内插入新数据。怎么阻止？就是把这个“范围”给锁住。
>
> 3. InnoDB 的“终极武器”：Next-Key Lock
>
>    为了锁住一个范围，InnoDB 发明了临键锁 (Next-Key Lock)。它非常霸道，因为它 = 行锁 (Record Lock) + 间隙锁 (Gap Lock)。
>
>    - **行锁**：锁定某条已经存在的记录。
>    - **间隙锁**：锁定两个索引记录之间的“空隙”，防止新记录插入。
>    - **临键锁**：同时锁定记录本身和它之前的那个间隙。例如，一个索引有 10, 20, 30 三个值，`(10, 20]` 就是一个临键锁区间。它既锁住了 20 这条记录，也锁住了 10 到 20 之间的空隙。
>
> > **记忆逻辑的第一步**：为了防止幻读，InnoDB 默认情况下倾向于使用最强的 Next-Key Lock，因为它既能锁住数据，又能锁住间隙，万无一失。
>
> ------
>
> ### 二、优化原则：“杀鸡焉用牛刀”的锁退化
>
> 虽然 Next-Key Lock 很安全，但它也锁住了不必要的范围，降低了并发性。因此，InnoDB 引入了优化机制：
>
> > **核心思想**：如果 InnoDB 判断出，使用更弱的锁（单纯的行锁或间隙锁）就已经**足够防止幻读**了，那么它就会将 Next-Key Lock “退化”成更弱的锁，从而提高并发。
>
> 所有的加锁规则，都是围绕着 **“默认用 Next-Key Lock，但在特定条件下可以安全地退化”** 这一核心逻辑展开的。
>
> ------
>
> ### 三、场景分析：庖丁解牛四种核心场景
>
> #### 场景一：唯一索引 + 等值查询
>
> 这是最容易优化的场景。
>
> - **1. 记录存在 (`WHERE id = 10;` 且 id=10 的记录存在)**
>   - **行为**：Next-Key Lock **退化为 Record Lock**。
>   - **为什么？** 查询条件是 `id = 10`，并且 `id` 是唯一索引。这意味着全天下不可能再有第二条 `id = 10` 的记录被插入了（会被数据库的唯一性约束拒绝）。既然插入 `id = 10` 的路已经被唯一索引堵死，我自然就**不需要用间隙锁来防止 `id = 10` 的幻读**。因此，只锁住 `id = 10` 这一行就足够了。Next-Key Lock 成功退化，并发性提高。
> - **2. 记录不存在 (`WHERE id = 11;` 且 id=11 的记录不存在)**
>   - **行为**：Next-Key Lock **退化为 Gap Lock**。
>   - **为什么？** 假设索引中有 10 和 20。我要找 `id = 11`，发现它不存在。我的目标是防止其他事务 `INSERT` 一条 `id = 11` 的记录进来。我需要锁住 `(10, 20)` 这个间隙。这里根本没有 `id = 11` 这条记录给我加行锁，所以 Next-Key Lock 中“锁记录”的部分是多余的。因此，它退化为只锁间隙的 Gap Lock。
>
> #### 场景二：唯一索引 + 范围查询
>
> - **行为**：大部分情况下加 **Next-Key Lock**，但在扫描到范围的“终点”时可能退化。
> - **为什么？** 范围查询（如 `WHERE id > 15 AND id < 25`）的目标是锁定一个区间，防止任何新记录插入这个区间。这正是 Next-Key Lock 的用武之地。
>   - 它会扫描 `id > 15` 的第一条记录（比如是 20），给它加上 Next-Key Lock，锁住 `(15, 20]`。
>   - 再扫描下一条（比如是 30），因为它已经超出了 `id < 25` 的范围，查询停止。但是，为了防止有数据插入到 `(20, 30)` 并且满足 `id < 25` 的条件（比如插入一个 24），InnoDB 必须把 `(20, 30)` 这个间隙也锁上。所以它会对 30 这条记录加锁，但因为查询条件是 `< 25`，30 这条记录本身不需要被锁，所以这个 Next-Key Lock 会**退化成 Gap Lock**，只锁 `(20, 30)` 间隙。
>
> #### 场景三：非唯一索引 + 等值查询
>
> 这是最复杂、也最能体现“初心”的场景。
>
> - **行为**：对所有满足条件的二级索引记录加 **Next-Key Lock**，并对它们对应的主键索引加 **Record Lock**。对扫描到的第一个不满足条件的记录，其 Next-Key Lock 会**退化为 Gap Lock**。
> - **为什么加 Next-Key Lock？** 假设查询 `WHERE age = 30;`，`age` 是非唯一索引。即使你找到了几条 `age = 30` 的记录并锁住了它们，由于索引不唯一，别的事务**仍然可以插入新的 `age = 30` 的记录**（只要主键不同）。这就导致了幻读。为了防止这种情况，必须用 Next-Key Lock 锁住 `age = 30` 记录本身以及它旁边的间隙，杜绝任何新的 `age = 30` 插进来。
> - **为什么还要锁主键？** 只锁二级索引是不够的。如果另一个事务通过主键来 `UPDATE` 或 `DELETE` 这条记录，行就不见了。所以，必须对找到的记录，在它的主键索引上也加上 Record Lock，保证这条记录跑不掉。
> - **为什么最后退化为 Gap Lock？** 和唯一索引的范围查询类似。当扫描完所有 `age = 30` 的记录，找到下一个 `age = 40` 的记录时，InnoDB 知道 `(30, 40)` 这个间隙也必须锁住，以防有新的 `age = 30` 插进来。但 `age = 40` 本身不符合查询条件，锁住它没有意义，所以施加在 `age = 40` 上的 Next-Key Lock 退化为 Gap Lock。
>
> #### 场景四：非唯一索引 + 范围查询
>
> - **行为**：对扫描范围内的所有二级索引记录加 **Next-Key Lock**，并对它们对应的主键索引加 **Record Lock**。**基本不退化**。
> - **为什么？** 这是最“绝望”的场景。范围查询 + 非唯一索引，意味着新数据可能从范围内的任何一个角落冒出来。InnoDB 没有任何可以优化的捷径，因为它无法预知哪里会插入满足条件的新数据。为了万无一失地防止幻读，它只能对扫描路径上的每一条索引记录都施加最强的 Next-Key Lock。这是一个纯粹的“宁可错杀一千，不可放过一个”的策略。
>
> ------
>
> ### 四、总结与记忆逻辑
>
> 你可以按照下面这个更清晰的逻辑路径来记忆：
>
> 1. **首要目标是什么？**
>    - 在 RR 级别下**防止幻读**。
> 2. **默认武器是什么？**
>    - **Next-Key Lock (行锁 + 间隙锁)**，因为它能同时锁住记录和间隙，最保险。
> 3. **何时可以优化（退化）？**
>    - 当**数据库或查询条件本身**已经能保证不会出现幻读时，就可以退化锁。
> 4. **决策树：**
>    - **查询命中唯一索引吗？**
>      - **是 ->** 唯一性约束是我们的好帮手！
>        - **等值查询 & 记录存在？** -> 唯一性保证了不会有新记录插入，**退化为 Record Lock**。
>        - **等值查询 & 记录不存在？** -> 只需防止插入，**退化为 Gap Lock**。
>        - **范围查询？** -> 范围内的间隙仍需保护，老老实实加 **Next-Key Lock**，但在扫描终点可以优化。
>      - **否 (非唯一索引) ->** 没有唯一性约束帮忙，必须自己锁好间隙。
>        - **等值查询？** -> 相同的索引值可能被重复插入，必须用 **Next-Key Lock** 锁住间隙。同时别忘了在**主键上加 Record Lock**。
>        - **范围查询？** -> 这是最不确定的情况，新数据可能出现在范围内的任何地方。放弃幻想，对扫描到的所有记录都上 **Next-Key Lock**。
>
> 这个逻辑链条从“为什么”出发，推导出“怎么做”，希望能帮助你更深刻、系统地理解 InnoDB 的加锁机制。



## 日志

### undo log

维护了事物的原子性，主要用于事物回滚和mvcc

在事物没提交之前，mysql会记录对应操作的undolog，本质就是构造一条与已经执行的sql语句相反的语句

插入时，记录主键，在回滚时只要删除对应记录即可

删除时，记录这条数据的内容，回滚时只要将这条数据插回去就行

更新的时候，记录该记录的旧值，回滚时只要恢复旧值即可

> #### delete时会有些特殊
>
> 他不会立即删除，而是逻辑删除
>
> #### update时
>
> - 如果不是主键列，直接在undolog中记录反向操作。既update是直接进行的
> - 如果是主键列，update会分两步，先删除目标行，再插入修改后的行

每一条undolog日志都有个roll_pointer指针和trx_id（事物id）

![image-20250807132702453](/assets/images/mysql/image-20250807132702453.png)





### redo log

维护了事物的持久性，主要用于掉电恢复**（没有保存全量数据，只保存了掉电前没提交的那些数据，因为redolog的文件大小是有限的，要全量恢复只能用binlog）**

他就是个`物理日志`

![image-20250807133512739](/assets/images/mysql/image-20250807133512739.png)

> 为什么一定要记录到redolog？直接落盘不行吗

- 日志写入是`顺序写`，磁盘写入是`随机写`，顺序写更快
- 这样还保证了数据的持久性

> redolog何时落盘？

redolog也是有自己的redolog buffer的，先写到这里面，这时候还是在内存中，没有落盘

- MySQL 正常关闭时； 

- 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘； 

- InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。 

- 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。

![image-20250807134329419](/assets/images/mysql/image-20250807134329419.png)



> redolog文件写满了怎么办

redolog文件组是由两个redolog文件构成，并且是**循环写**， 默认大小为每个文件1G，也可以自定义大小

### bin log

**Binlog 格式类型详解**

| 格式类型      | 描述                               | 优点                       | 缺点                                                         | 适用场景                     |
| ------------- | ---------------------------------- | -------------------------- | ------------------------------------------------------------ | ---------------------------- |
| **STATEMENT** | 记录每条 SQL 语句（逻辑操作）      | binlog 文件小，执行效率高  | 动态函数（如 `NOW()`、`UUID()`）在主从执行结果可能不同，导致数据不一致 | 适合无动态函数的业务逻辑     |
| **ROW**       | 记录每行数据的变更结果（物理操作） | 数据一致性强，不受函数影响 | binlog 文件大，尤其是批量操作时                              | 适合对数据一致性要求高的场景 |
| **MIXED**     | 自动选择使用 STATEMENT 或 ROW      | 兼顾效率与一致性           | 实现复杂，调试困难                                           | 通用场景，推荐默认使用       |

建议：

- 对一致性要求高的业务（如金融系统）使用 **ROW**；
- 对性能要求高且业务逻辑简单的系统使用 **STATEMENT**；
- 默认推荐使用 **MIXED**，适合大多数场景。









## 两阶段提交

### 为什么要二阶段提交？？

#### 1. **Redo Log 与 Binlog 的一致性**

```sql
-- 假设这样一个更新操作
UPDATE user SET balance = balance - 100 WHERE id = 1;
```

**没有2PC的问题场景：**

- Redo Log写入成功 → 服务器crash → Binlog未写入
- 结果：主库数据已更新，但从库无法同步，造成**主从不一致**

#### 2. **事务的原子性保障**

确保一个事务要么完全成功，要么完全失败，不会出现部分成功的情况。



### 写入机制

binlog的写入时机也非常简单，事务执行过程中，先把日志写到binlog cache ，事务提交的时候，再把binlog cache写到binlog文件中。因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache。

![image-20250529112901220](/assets/images/mysql/image-20250529112901220.png)

### binlog刷盘机制

MySQL提供一个 sync binlog 参数来控制数据库的 binlog 刷到磁盘上的频率:

- sync_binog =0的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘;
- sync_binlog =1的时候，表示每次提交事务都会 write，然后马上执行 fsync;
- sync binlog =N(N>1)的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

### binlog与redolog对比

| 对比维度         | Redo Log（重做日志）                                         | Binlog（二进制日志）                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **日志层级**     | InnoDB 存储引擎层日志（仅 InnoDB 可用）                      | MySQL 服务器层日志（所有引擎通用，如 MyISAM、InnoDB）        |
| **核心目标**     | 保证事务的 **持久性（ACID 中的 D）** + 崩溃恢复              | 实现 **数据备份** + **主从复制**                             |
| **日志内容**     | 物理日志：记录“对哪个数据页（Page ID）做了什么修改”（如“页 1024 的偏移量 50 写入值 'abc'”） | 逻辑日志：记录“数据变更的逻辑操作”（如“INSERT INTO t VALUES (1,'a')”，或“行记录 before/after 变化”） |
| **写入时机**     | 事务执行过程中 **实时写入**（每修改一个页就写），事务提交时刷盘（可配置刷盘策略） | 事务提交后 **一次性写入**（先写内存缓冲区，满足条件后刷盘）  |
| **日志生命周期** | 循环写（固定大小，满了覆盖旧日志），仅保留“未刷盘到数据文件的修改” | 追加写（生成多个文件，不覆盖），可长期保存（用于历史恢复）   |
| **适用场景**     | 数据库崩溃后，快速恢复内存中未刷盘的脏页数据                 | 1. 主从复制：主库传 Binlog 给从库，从库重放同步数据；2. 时间点恢复：结合全量备份，恢复到任意历史时间点 |

- redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎层产生的。
- 而 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。
- 虽然都是持久化的保证，但侧重点不同：
  - redo log主要保证持久性（主要为了防止MySql运行过程中还未刷盘就挂了，所以在把内存页标记为脏页的同时就完成了redo log的写入缓存，等事务提交就刷盘，如果事务未提交，也就不需要记录该条事务的内容）
  - bin log主要保证故障恢复，主从复制（bin log中主要记录对数据的增删改操作，等事务提交就write写入os缓存，由os决定何时落盘，如果事务未提交，也就不需要记录该条事务的内容）

![image-20250529113246226](/assets/images/mysql/image-20250529113246226.png)

### 两阶段提交的原理

在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样。

![image-20250529115008583](/assets/images/mysql/image-20250529115008583.png)

此时MySql的主机已经提交了事务，并且完成了redo log的落盘，但binlog没落盘，主机的数据是没问题的，但是从机进行主从复制是根据binlog文件来的，所以会导致主从数据不一致。如下图。

![image-20250529115250390](/assets/images/mysql/image-20250529115250390.png)

**为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。**

![image-20250529121054050](/assets/images/mysql/image-20250529121054050.png)

从图中可看出，事务的提交过程有两个阶段，就是将redo log 的写入拆成了两个步骤:prepare 和commit，中间再穿插写入binlog，具体如下:

- **prepare 阶段:**将 XID(内部 XA 事务的 ID)写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，**然后将 redo log 持久化到磁盘(innodb flush log_at trx_commit=1的作用)**;`redo log落盘成功`
- **commit 阶段:**
  - 把 XID 写入到 binlog，**然后将 binlog 持久化到磁盘(sync binlog=1的作用)**，`binlog 落盘成功`
  - 接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是prepare 也没有关系，一样会被认为事务已经执行成功;



异常重启的不同情况：

![image-20250529122718357](/assets/images/mysql/image-20250529122718357.png)

> 在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的XID 去 binlog 查看是否存在此 XID:
>
> - **如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务**。对应时刻 A 崩溃恢复的情况。
> - **如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。**对应时刻 B 崩溃恢复的情况。
>
> 
>
> 可以看到，对于处于 **prepare 阶段**的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这样就可以保证redo log 和 binlog 这两份日志的一致性了。
>
> 
>
> 所以说，**两阶段提交是以 binlog 写成功为事务提交成功的标识**，因为 binlog 写成功了，就意味着能在binlog 中查找到与 redo log 相同的 XID。

> 如果写入binlog成功但redo log设置redolog的commit阶段发生异常，那他重启后也会先判断是否是commit阶段，这种情况下答案是yes，接着判断是否存在对应的binlog，存在就直接提交事务

总结： **redo log 可以在事务没提交之前持久化到磁盘，但是 binlog 必须在事务提交之后(完成prepare阶段的redo log，开始提交事务后)，才可以持久化到磁盘。**

### 两阶段提交的问题

![image-20250529124514383](/assets/images/mysql/image-20250529124514383.png)

![image-20250529124757896](/assets/images/mysql/image-20250529124757896.png)

## 主从复制

主从复制就是正在MySql集群中，实现读写分离时使用到的技术。

主要流程是这样的，首先有事务正在更改主库的数据，在修改事务提交后，主库会将对应修改写入binlog日志中，从库会使用该binlog日志进行数据同步。

有三种同步方式：

- 全同步：主库会分配一个log dump线程向从库发送binlog，从库中会有个IO线程来接收，并计入从库的`delay log`中，最后进行重放来恢复数据，最后给主库返回处理结果的状态信息
- 异步：主库会分配一个log dump线程向从库发送binlog，一旦发送完毕，就将处理结果返回客户端，不等从库完成同步

> ​    因为主库只管自己执行完事务，就可以将处理结果返回给客户端，而不用关心从库是否执行完事务，这就可能导致短暂的主从数据不一致的问题了，比如刚在主库插入的新数据，如果马上在从库查询，就可能查询不到。    
>
> ​    而且，当主库提交事物后，如果宕机挂掉了，此时可能 binlog 还没来得及同步给从库，这时候如果为了恢复故障切换主从节点的话，就会出现数据丢失的问题，所以异步复制虽然性能高，但数据一致性上是最弱的。

- 半同步：至少等待一个从库同步成功才继续往下执行

> 这样做的好处就是提高了数据的一致性，当然相比于异步复制来说，至少多增加了一个网络连接的延迟，降低了主库写的效率。

![image-20250530095505895](/assets/images/mysql/image-20250530095505895.png)

- 增强半同步复制

> 增强半同步复制，是 MySQL 5.7.2后的版本对半同步复制做的一个改进，原理上几乎是一样的，主要是解决幻读的问题。主库配置了参数 rpl_semi_sync_master_wait_point = AFTER_SYNC 后，主库在存储引擎提交事务前，必须先收到从库数据同步完成的确认信息后，才能提交事务，以此来解决幻读问题。

![image-20250530095626733](/assets/images/mysql/image-20250530095626733.png)

## 分库分表

### 两种分库分表的方式：

- 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如**时间范围**来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。
- 或者是按照某个字段 hash 一下均匀分散，这个较为常用。

range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。

hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。（可以使用一致性哈希来优化）

### 分库分表如何平滑过渡？

#### 双写迁移方案

在线上系统里面，之前所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**，这就是所谓的**双写**，同时写俩库，老库和新库。

然后**系统部署**之后，新库数据差太远，用之前说的导数工具，根据 gmt_modified 这类字段判断这条数据最后修改的时间来前迁移数据，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。

简单来说，就是**不允许用老数据覆盖新数据**。



这样迁移完一轮之后，可能还是有不一样的，那就再扫一遍，针对不一样的，再去老库里找数据去更新

![image-20250826130705157](/assets/images/mysql/image-20250826130705157.png)





## 分布式ID（还没看）

在分布式那个文档里

## 分布式锁（还没看，优先看）



## 慢查询日志

参考：[19 如何根治慢 SQL？](https://learn.lianglianglee.com/专栏/说透性能测试/19  如何根治慢 SQL？.md)

> Slow_query_log=1: 开启慢查询日志
>
> Long_query_time = 2. 超过这个时间就被视为慢查询
>
> Show variables like 'slow_query_log'

找到对应的sql语句，然后explain

| 字段         | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| id           | select查询的序列号，表示查询中执行select子句或者是操作表的顺序<br/>(id相同，执行顺序从上到下；id不同，值越大，越先执行)。 |
| select_type  | 表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（SELECT/WHERE之后包含了子查询）等 |
| type         | 表示连接类型，性能由好到差的连接类型为NULL、system、const、eq_ref、ref、range、 index、all 。 |
| possible_key | 显示可能应用在这张表上的索引，一个或多个。                   |
| key          | 实际使用的索引，如果为NULL，则没有使用索引。                 |
| key_len      | 表示索引中使用的字节数， 该值为索引字段最大可能长度，并非实际使用长度，在不损失精确性的前提下， 长度越短越好 。 |
| rows         | MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值，可能并不总是准确的。 |
| filtered     | 表示返回结果的行数占需读取行数的百分比， filtered 的值越大越好。 |

---

## Join 优化实战案例

### 问题场景：小表驱动大表

```sql
-- 两个表关联查询
-- orders 表：50 万行，user_id 字段无索引
-- users 表：10 万行，id 是主键
EXPLAIN SELECT *
FROM orders o
LEFT JOIN users u ON o.user_id = u.id
WHERE o.status = 1;

-- 执行计划（rows 很大，全表扫描）
+----+-------+--------+------+---------------+---------+---------+----------------+--------+-------------+
| id | type  | table  | type | possible_keys | key     | key_len | ref            | rows   | Extra       |
+----+-------+--------+------+---------------+---------+---------+----------------+--------+-------------+
|  1 | ALL   | o      | ALL  | NULL          | NULL    | NULL    | NULL           | 500000 | Using where |
|  1 | ALL   | u      | ALL  | PRIMARY       | NULL    | NULL    | NULL           | 100000 | Using where |
+----+-------+--------+------+---------------+---------+---------+----------------+--------+-------------+
```

**问题分析：**
- 两个表都是 `type = ALL`，全表扫描
- Join 操作产生了笛卡尔积（500000 × 100000 = 500 亿行）
- **关键问题**：被驱动表（orders）的 Join 字段上没有索引

### 优化方案

**步骤 1：在被驱动表的关联字段上加索引**

```sql
-- 在 orders 表的 user_id 字段上建索引
CREATE INDEX idx_user_id ON orders(user_id);
```

**步骤 2：优化 SQL（小表驱动大表）**

```sql
-- 改写为 INNER JOIN，让优化器自动选择小表作为驱动表
-- 添加过滤条件，减少参与 Join 的数据量
EXPLAIN SELECT *
FROM users u
INNER JOIN orders o ON o.user_id = u.id
WHERE o.status = 1
AND u.create_time > '2024-01-01';

-- 优化后的执行计划
+----+--------+--------+--------+---------------+-------------+---------+----------------+------+-------+
| id | type   | table  | type   | possible_keys | key         | key_len | ref            | rows | Extra |
+----+--------+--------+--------+---------------+-------------+---------+----------------+------+-------+
|  1 | ALL    | u      | ALL    | PRIMARY       | NULL        | NULL    | NULL           |  100 | Using where |
|  1 | ref    | o      | ref    | idx_user_id   | idx_user_id | 4       | db.u.id        |   50 | Using where |
+----+--------+--------+--------+---------------+-------------+---------+----------------+------+-------+
```

### 优化效果对比

| 指标 | 优化前 | 优化后 | 提升 |
|------|--------|--------|------|
| 扫描行数 | 500000 × 100000 = 500 亿 | 100 × 50 = 5000 | **100 万倍** |
| type | ALL (全表扫描) | ref (索引查找) | ✅ |
| 执行时间 | 120 秒 | 0.5 秒 | **240 倍** |

### Join 优化核心要点

**1. 小表驱动大表**
- **驱动表**（外层循环）：数据量小的表
- **被驱动表**（内层循环）：数据量大的表
- 原理：减少外层循环次数

```sql
-- ❌ 错误：大表驱动小表
SELECT * FROM orders o    -- 50 万行
JOIN users u ON o.user_id = u.id;  -- 10 万行

-- ✅ 正确：小表驱动大表
SELECT * FROM users u     -- 10 万行
JOIN orders o ON o.user_id = u.id;  -- 50 万行
```

**2. 在被驱动表的 Join 字段上加索引**
- 索引应该加在**被驱动表**的关联字段上
- 本例：`orders.user_id` 上加索引

**3. 选择合适的 Join 类型**

| Join 类型 | 特点 | 使用场景 |
|-----------|------|----------|
| INNER JOIN | 只返回匹配的行，优化器可自由选择驱动表 | **推荐**，性能最优 |
| LEFT JOIN | 左表所有行都要保留，左表必须是驱动表 | 必须保留左表全部数据时 |
| STRAIGHT_JOIN | 强制左表为驱动表，禁止优化器重排序 | 明确知道哪个表更小时 |

**4. 避免使用 SELECT ***

```sql
-- ❌ 查询所有字段，大量回表操作
SELECT * FROM users u JOIN orders o ON u.id = o.user_id;

-- ✅ 只查询需要的字段，可能使用覆盖索引
SELECT u.name, o.order_id, o.amount
FROM users u JOIN orders o ON u.id = o.user_id;
```

### EXPLAIN 中如何判断 Join 性能？

**关注以下字段：**

| 字段 | 好的指标 | 坏的指标 |
|------|----------|----------|
| **type** | eq_ref、ref | ALL、index |
| **rows** | 越小越好 | > 10000 |
| **Extra** | Using where、Using index | Using temporary |

**eq_ref vs ref：**
- **eq_ref**：主键或唯一索引等值连接，每行只匹配一行（最优）
- **ref**：非唯一索引等值连接，可能匹配多行

```sql
-- eq_ref 示例（最优）
-- users.id 是主键，orders.user_id 有索引
SELECT * FROM orders o JOIN users u ON o.user_id = u.id;
-- u 表的 type = eq_ref（每行只匹配一个 user）

-- ref 示例（良好）
-- orders.user_id 有索引，但不是唯一索引
SELECT * FROM users u JOIN orders o ON u.user_id = u.id;
-- o 表的 type = ref（一个 user 可能有多个 orders）
```

### 面试必问：为什么小表驱动大表？

**原理：嵌套循环连接（Nested-Loop Join）**

```sql
-- 小表驱动大表的执行过程
for each row in 小表:          -- 外层循环 100 次
    for each row in 大表:      -- 内层循环 5000 次
        if 匹配 then 输出
-- 总比较次数：100 × 5000 = 50 万次

-- 大表驱动小表的执行过程
for each row in 大表:          -- 外层循环 5000 次
    for each row in 小表:      -- 内层循环 100 次
        if 匹配 then 输出
-- 总比较次数：5000 × 100 = 50 万次
```

**看起来一样？关键在于索引！**

```sql
-- 如果被驱动表（大表）有索引
for each row in 小表:          -- 外层循环 100 次
    在大表的索引中查找（O(log N)）   -- 索引查找，非常快
-- 总比较次数：100 × log(5000) ≈ 1400 次（快得多！）
```

**结论：小表驱动大表 + 被驱动表有索引 = 最优方案**

---

# 不熟悉的面试题

## Exist和In的区别？

IN的执行流程：

- 先执行IN后面的子查询，然后保存为一个**临时表**
- 然后执行外面的查询，对于每一条外部查询的记录，都会去临时表里找一遍

EXIST的执行流程：

- 先执行外部查询，每查出一条数据，都去内部查询里查一次
- 只检查存在性，只要有一次查到了，子查询返回True，否则返回False
- EXIST在得到True的时候，会保留当前一行数据



### 何时使用：性能考量

基于上述原理，我们可以得出经典的 "谁大谁小" 法则，但这背后真正的关键是**索引**。

#### 经典的 "谁大谁小" 法则

1. **`IN` 适用场景：内表 (B) 小，外表 (A) 大**
   - **原因:** `IN` 会先把内表B的结果集加载到内存。如果B表很小，这个内存集合（Hash Set）就很小。外表A虽然大，但每次只是和这个小集合做快速的哈希查找（时间复杂度近乎 $O(1)$），总效率很高。
   - **反例:** 如果内表B非常大，`IN` 会导致内存占用过高，且创建这个巨大集合的过程本身就很慢。
2. **`EXISTS` 适用场景：外表 (A) 小，内表 (B) 大**
   - **原因:** `EXISTS` 是以外表A为驱动（外层循环）。如果A表很小，那么子查询（内层循环）的执行次数就很少。
   - **关键:** 此时，即使B表非常大，**只要B表在关联字段上（如 `B.a_id`）有<u>*索引*</u>**，每次内层循环都是一次极快的索引查找（Index Seek），总效率也会非常高。

------

#### 更现代、更准确的法则：看索引！

在现代的MySQL优化器（如 5.6, 8.0）中，`IN` 和 `EXISTS` 经常会被优化器重写为对方或 `JOIN`（特别是 `SEMI-JOIN`）。

因此，"谁大谁小" 法则不再是金标准，**索引才是决定性因素**：

- EXISTS 的杀手锏：内表索引

  如果 EXISTS 的子查询的 WHERE 条件中，用于和外表<u>*关联的字段有索引*</u>（如 B.a_id = A.id 中的 B.a_id），那么 EXISTS 几乎总是高效的。它相当于执行了 N (A表行数) 次快速的索引查找。

- IN 的优势：内表结果集小

  如果子查询的结果集（B）非常小，IN 的效率很高。

- IN 的陷阱：NOT IN 与 NULL

  这是一个非常重要的区别：

  - `NOT IN`：如果子查询 `IN` 的结果集中**包含任何 `NULL` 值**，`NOT IN` 的结果将永远为 `FALSE`（技术上是 `UNKNOWN`），导致外层查询*一行也查不出来*。这是一个巨大的陷阱。
  - `NOT EXISTS`：完全没有 `NULL` 值问题，它只关心"是否存在"。

  **结论：应始终使用 `NOT EXISTS` 来代替 `NOT IN`。**



关于NOT IN，其实是这样的，not in后面的集合里不能有NULL

因为not in 的判断逻辑是转化成 ！= ，然后再 &&， 如果有null，那就会导致not in 返回的结果是UNKNOW。又因为where只保留判断为True的记录，所以就会出问题

> #### 1. 准备数据
>
> Students (学生表)
>
> Leave_Students (已退学学生表)
>
> - Alice (id=1) 已经退学了。
> - `NULL` 这条记录可能是因为数据录入错误，或者某个流程出错了，但它**真实地存在**于数据库中。
>
> #### 2. 执行你的查询 (使用 `NOT IN`)
>
> 根据你的逻辑，你写出了如下SQL：
>
> ```sql
> SELECT *
> FROM Students
> WHERE id NOT IN (
>     SELECT student_id FROM Leave_Students
> );
> ```
>
> 你的预期结果：
>
> 你期望 id=1 (Alice) 被过滤掉，因为她在退学列表里。
>
> 你期望 id=2 (Bob) 和 id=3 (Charlie) 被返回，因为他们不在退学列表里。
>
> | **id** | **name** |
> | ------ | -------- |
> | 2      | Bob      |
> | 3      | Charlie  |
>
> 实际的查询结果：
>
> 查询返回 0 行。
>
> (空结果集)
>
> ------
>
> #### 3. 后果分析 (为什么？)
>
> `NOT IN` 查询 `... WHERE id NOT IN (1, NULL)` 发生了什么？
>
> 我们来逐行检查 `Students` 表中的学生：
>
> **1. 检查 `id=1` (Alice):**
>
> - `WHERE 1 NOT IN (1, NULL)`
> - 等价于：`WHERE (1 != 1) AND (1 != NULL)`
> - 计算：`FALSE AND UNKNOWN`
> - **结果：`FALSE`** (Alice 被丢弃，这符合预期)
>
> **2. 检查 `id=2` (Bob):**
>
> - `WHERE 2 NOT IN (1, NULL)`
> - 等价于：`WHERE (2 != 1) AND (2 != NULL)`
> - 计算：`TRUE AND UNKNOWN`
> - **结果：`UNKNOWN`** (Bob 被丢弃，**这是灾难性的错误！**)
>
> **3. 检查 `id=3` (Charlie):**
>
> - `WHERE 3 NOT IN (1, NULL)`
> - 等价于：`WHERE (3 != 1) AND (3 != NULL)`
> - 计算：`TRUE AND UNKNOWN`
> - **结果：`UNKNOWN`** (Charlie 也被丢弃，**同样是灾难性的错误！**)
>
> 后果：
>
> 你本想获取一个仍在校学生（Bob 和 Charlie）的列表，用来给他们发奖学金或注册课程。但因为退学表里有一条脏数据 NULL，你的 NOT IN 查询返回了 0 个人。
>
> **你以为系统里没有在校学生了！**
>
> 这是一个非常隐蔽的Bug，它不会报错，它只会默默地返回错误（空）的数据，这在业务系统中可能导致严重的数据不一致或流程中断。
>
> #### 4. 正确的规避方法
>
> **方法一：使用 `NOT EXISTS` (推荐)**
>
> `NOT EXISTS` 不关心 `NULL` 值，它只检查是否存在匹配行。
>
> ```sql
> SELECT *
> FROM Students s
> WHERE NOT EXISTS (
>     SELECT 1
>     FROM Leave_Students l
>     WHERE l.student_id = s.id -- 这里是关键
> );
> ```
>
> **执行分析：**
>
> 1. **检查 `id=1` (Alice):** 子查询 `... WHERE l.student_id = 1` 能找到一行。`EXISTS` 返回 `TRUE`。`NOT EXISTS` 变为 `FALSE`。Alice被丢弃。 (正确)
> 2. **检查 `id=2` (Bob):** 子查询 `... WHERE l.student_id = 2` 找不到行 ( `1 = 2` 是 `FALSE`，`NULL = 2` 是 `UNKNOWN` )。`EXISTS` 返回 `FALSE`。`NOT EXISTS` 变为 `TRUE`。Bob被保留。 (正确)
> 3. **检查 `id=3` (Charlie):** 同理，`EXISTS` 返回 `FALSE`。`NOT EXISTS` 变为 `TRUE`。Charlie被保留。 (正确)
>
> NOT EXISTS 的正确结果：
>
> | id | name |
>
> | :--- | :--- |
>
> | 2 | Bob |
>
> | 3 | Charlie |
>
> **方法二：在 `NOT IN` 中手动排除 `NULL`**
>
> ```SQL
> SELECT *
> FROM Students
> WHERE id NOT IN (
>     SELECT student_id FROM Leave_Students WHERE student_id IS NOT NULL
> );
> ```
>
> 这个查询现在等价于 `WHERE id NOT IN (1)`，它也能返回 Bob 和 Charlie，但你必须时刻记得去排除 `NULL`，远不如 `NOT EXISTS` 来得省心和安全。



## Innodb中是如何保存数据的null值的

我的理解是：
在每一行数据中都会有一些隐藏字段，其中有个`null值列表`，最少占用1字节的空间，其中以二进制的形式来保存每一列是否是空值

- 每一个二进制位为1就说明是null，0就代表非空

![image-20251106154802704](/assets/images/mysql/image-20251106154802704.png)

## 为什么隐藏字段的信息要逆序存放？

假设 cache缓存的数据是蓝色框的内容。这样记录1的变成字段长度和记录1在一个cpu cache中了。如果变长字段不是逆袭存储的话,这种情况,记录1的变成字段长度和记录1就不在一个cpu cache中了

![image-20251106154920033](/assets/images/mysql/image-20251106154920033.png)

个人理解就是尽可能的让同一个列的信息尽量挨得近点，这样能更容易被固定大小的CPU cache读到，提高命中率，从而提高性能。



## 假如说一个字段是varchar(10),但它其实只有6个字节,那他在内存中占的存储空间是多少?在文件中占的存储空间是多少?

![image-20251106155357825](/assets/images/mysql/image-20251106155357825.png)

内存会占用10字节,文件存储空间会占用6字节,并且还会额外用1-2字节存储「可变长字符串长度」的空间。
---
## 🔥 MySQL Top 20 面试题速查
[内容很长，直接追加到文件末尾]

---

## 🔥 MySQL Top 20 面试题速查

### 一、索引原理篇（1-5）

**1. 为什么 MySQL 索引使用 B+ 树而不是 B 树、哈希表？**

| 数据结构 | 优点 | 缺点 | MySQL 是否使用 |
|---------|------|------|---------------|
| **B+ 树** | 叶子节点有指针，范围查询效率高；非叶子节点只存索引，可以存更多索引 | - | ✅ InnoDB 默认 |
| **B 树** | - | 范围查询需要中序遍历，效率低 | ❌ |
| **哈希表** | 等值查询 O(1) | 不支持范围查询；哈希冲突处理复杂 | ✅ Memory 引擎 |
| **二叉树** | - | 树的高度高，磁盘 I/O 次数多 | ❌ |

**面试要点**：
- B+ 树非叶子节点只存索引，一页（16KB）可以存更多索引，树更矮胖，减少磁盘 I/O
- B+ 树叶子节点用双向链表连接，范围查询效率高（如 `BETWEEN`, `>`, `<`）

---

**2. 聚簇索引 vs 非聚簇索引（二级索引）的区别？**

| 特性 | 聚簇索引（主键索引） | 非聚簇索引（二级索引） |
|------|---------------------|---------------------|
| **数量** | 1 个表只有 1 个 | 1 个表可以有多个 |
| **存储内容** | 完整的数据行 | 索引列 + 主键值 |
| **叶子节点** | 直接存储数据行 | 存储主键值（需要回表） |
| **大小** | 通常较大 | 相对较小 |

**回表查询**：
```sql
-- 二级索引查询过程
SELECT * FROM users WHERE name = 'Alice';
-- 1. 在 name 索引树中找到 'Alice'，得到主键 id = 123
-- 2. 到主键索引树中查找 id = 123 的完整数据行（回表）
-- 性能优化：使用覆盖索引（SELECT 时只查询索引列和主键）
```

---

**3. 什么是覆盖索引？如何优化？**

**定义**：如果查询的列正好是索引的列，直接从索引获取数据，不需要回表。

```sql
-- 假设有索引 (name, age)

-- ❌ 需要回表
SELECT * FROM users WHERE name = 'Alice';

-- ✅ 覆盖索引，不需要回表
SELECT id, name, age FROM users WHERE name = 'Alice';

-- ✅ 覆盖索引优化
SELECT COUNT(*) FROM users WHERE name = 'Alice';  -- 只需扫描索引
```

**面试要点**：最常用的 SQL 优化手段之一，避免回表操作。

---

**4. 联合索引的最左前缀原则？**

**索引 `(a, b, c)` 的使用情况：**

| WHERE 条件 | 是否使用索引 | 使用的索引列 |
|-----------|------------|-------------|
| `WHERE a = 1` | ✅ | a |
| `WHERE a = 1 AND b = 2` | ✅ | a, b |
| `WHERE a = 1 AND b = 2 AND c = 3` | ✅ | a, b, c |
| `WHERE b = 2 AND c = 3` | ❌ | 无（跳过了 a） |
| `WHERE a = 1 AND c = 3` | ✅ | a（c 未使用） |
| `WHERE a = 1 AND b > 2 AND c = 3` | ✅ | a, b（c 失效，范围查询后索引失效） |

**面试要点**：
- 联合索引按顺序从左到右匹配
- 范围查询（`>`, `<`, `BETWEEN`）后的索引列失效
- `>=` 和 `<=` 不会导致后续索引失效（与 `>` 和 `<` 的区别）

---

**5. 什么情况下索引会失效？（10 种场景）**

1. **左/右模糊匹配**：`LIKE '%abc'` 失效，`LIKE 'abc%'` 生效
2. **对索引使用函数**：`WHERE AGE + 1 = 20` 失效
3. **隐式类型转换**：字符串字段用数字查询失效
4. **违反最左前缀**：联合索引跳过最左列
5. **OR 连接但只有一个字段有索引**：`WHERE a = 1 OR b = 2`（只有 a 有索引）失效
6. **不等于**：`!=`, `<>` 失效
7. **IS NOT NULL**：失效（IS NULL 可以用索引）
8. **范围查询后的字段**：`INDEX(a,b,c)` → `WHERE a=1 AND b>10 AND c=3`（c 失效）
9. **全表扫描更优**：扫描行数超过 30%，优化器自动放弃索引
10. **优化器错误选择**：统计信息不准确时（需 ANALYZE TABLE 更新）

---

### 二、事务与锁篇（6-10）

**6. MySQL 事务的 ACID 特性如何实现？**

| 特性 | 实现机制 | 说明 |
|------|---------|------|
| **原子性（A）** | Undo Log | 事务回滚时，用 Undo Log 恢复到修改前 |
| **一致性（C）** | 原子性 + 隔离性 + 持久性 | 由其他三个特性共同保障 |
| **隔离性（I）** | 锁机制 + MVCC | 读未提交、读已提交、可重复读、串行化 |
| **持久性（D）** | Redo Log + Binlog | 事务提交时，Redo Log 持久化到磁盘 |

---

**7. MVCC（多版本并发控制）的实现原理？**

**核心组件**：
1. **隐藏字段**：每行数据有 `trx_id`（事务 ID）和 `roll_pointer`（回滚指针）
2. **Undo Log**：记录数据的历史版本，通过 `roll_pointer` 串联成版本链
3. **Read View**：事务启动时生成的一致性视图，判断数据版本是否可见

**Read View 的可见性判断**：
```
最小活跃事务 ID ≤ trx_id ≤ 最大事务 ID
  ↓
如果 trx_id 在活跃事务列表中 → 不可见（未提交）
如果 trx_id 不在活跃事务列表中 → 可见（已提交）
```

**RC 和 RR 的区别**：
- **Read Committed**：每次 SELECT 都生成新的 Read View
- **Repeatable Read**：只在第一次 SELECT 时生成 Read View，后续复用

---

**8. InnoDB 的锁类型有哪些？**

| 锁类型 | 锁定对象 | 加锁方式 | 用途 |
|--------|---------|---------|------|
| **Record Lock** | 单行记录 | 行锁 | 保护单行数据 |
| **Gap Lock** | 索引间隙 | 间隙锁 | 防止幻读（插入新记录） |
| **Next-Key Lock** | 记录 + 间隙 | 行锁 + 间隙锁 | InnoDB 默认，防止幻读 |
| **意向锁（IS/IX）** | 表级 | 表锁 | 快速判断表是否有行锁 |
| **插入意向锁** | 插入位置 | 特殊间隙锁 | 多个事务可并发插入不同值 |

**面试要点**：
- Gap Lock 只在 RR 隔离级别下存在
- Gap Lock 之间兼容，目的是防止插入，不是防止读取
- 唯一索引等值查询，Next-Key Lock 会退化为 Record Lock

---

**9. 间隙锁（Gap Lock）的作用？**

**作用**：防止其他事务在间隙中插入新记录，解决幻读问题。

**示例**：
```sql
-- 表中有 id = 10, 20, 30 的记录
-- 事务 A
SELECT * FROM table WHERE id > 10 AND id < 20 FOR UPDATE;
-- 加上间隙锁 (10, 20)，阻止其他事务插入 id = 15

-- 事务 B
INSERT INTO table VALUES (15, 'data');  -- 阻塞，等待间隙锁释放
```

**关键特性**：
- 间隙锁之间不冲突（多个事务可以同时持有相同范围的间隙锁）
- 唯一目的是防止插入，不防止读取
- 只在 RR 隔离级别下生效

---

**10. 如何定位和解决死锁？**

**定位死锁**：
```sql
-- 查看最近一次死锁信息
SHOW ENGINE INNODB STATUS;

-- 在输出中查找 LATEST DETECTED DEADLOCK 部分
```

**解决死锁的方法**：
1. **设置锁等待超时**：`SET GLOBAL innodb_lock_wait_timeout = 30;`
2. **开启死锁检测**：`SET GLOBAL innodb_deadlock_detect = ON;`（默认开启）
3. **应用层优化**：
   - 统一访问顺序（避免循环等待）
   - 减小事务粒度（快进快出）
   - 添加合理索引（减少锁范围）

**面试要点**：死锁检测在高并发下会消耗 CPU，极端情况可以临时关闭，依靠超时机制。

---

### 三、日志与高可用篇（11-15）

**11. Redo Log vs Binlog 的区别？**

| 对比维度 | Redo Log | Binlog |
|---------|----------|--------|
| **日志层级** | InnoDB 存储引擎层 | MySQL Server 层 |
| **日志内容** | 物理日志（页的修改） | 逻辑日志（SQL 语句或行数据） |
| **写入时机** | 事务执行过程中实时写入 | 事务提交时写入 |
| **持久化策略** | `innodb_flush_log_at_trx_commit` | `sync_binlog` |
| **用途** | 崩溃恢复、保证持久性 | 主从复制、时间点恢复 |
| **循环写入** | ✅ 固定大小，循环写 | ❌ 追加写，不覆盖 |

**面试要点**：两阶段提交（2PC）保证 Redo Log 和 Binlog 的一致性。

---

**12. 两阶段提交（2PC）的目的是什么？**

**目的**：保证 Redo Log 和 Binlog 的一致性，防止主从数据不一致。

**流程**：
```
1. Prepare 阶段：写入 Redo Log，标记为 prepare 状态
2. 写入 Binlog
3. Commit 阶段：将 Redo Log 标记为 commit 状态
```

**崩溃恢复**：
- Redo Log 处于 prepare 状态，Binlog 没有 → 回滚事务
- Redo Log 处于 prepare 状态，Binlog 存在 → 提交事务
- Redo Log 处于 commit 状态 → 提交事务

---

**13. innodb_flush_log_at_trx_commit 和 sync_binlog 的最佳配置？**

**"双 1" 配置（最安全，性能最低）**：
```sql
SET GLOBAL innodb_flush_log_at_trx_commit = 1;  -- 每次事务提交刷盘
SET GLOBAL sync_binlog = 1;                      -- 每次事务提交刷盘
```

**性能优化配置（推荐生产环境）**：
```sql
-- 如果能容忍少量数据丢失
SET GLOBAL innodb_flush_log_at_trx_commit = 2;  -- 每秒刷盘一次
SET GLOBAL sync_binlog = 10;                     -- 每 10 个事务刷盘一次
```

---

**14. 主从复制的三种模式？**

| 模式 | 特点 | 优点 | 缺点 | 数据一致性 |
|------|------|------|------|-----------|
| **异步复制** | 主库不等待从库确认 | 性能最高 | 主库宕机可能丢数据 | 弱 |
| **半同步复制** | 至少等待一个从库确认 | 平衡性能和一致性 | 增加延迟 | 较强 |
| **全同步复制** | 等待所有从库确认 | 数据最强 | 性能最差 | 最强 |

---

**15. Binlog 的三种格式及选择？**

| 格式 | 记录内容 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|----------|
| **STATEMENT** | SQL 语句 | 文件小，节省空间 | 主从不一致（如 UUID()） | 简单业务 |
| **ROW** | 行数据变更 | 数据一致性最好 | 文件大，可能有 binlog 占用过多 | **生产环境推荐** |
| **MIXED** | 自动选择 | 平衡 | 调试困难 | 通用场景 |

**生产环境推荐**：`binlog_format = ROW`

---

### 四、实战优化篇（16-20）

**16. 如何优化慢查询？（通用步骤）**

```
1️⃣ 开启慢查询日志
   slow_query_log = 1
   long_query_time = 2

2️⃣ 分析慢查询日志
   mysqldumpslow -s t -t 10 /var/log/mysql/slow.log

3️⃣ 使用 EXPLAIN 分析执行计划
   关注：type、key、rows、Extra

4️⃣ 根据执行计划优化
   - 无索引 → 建索引
   - 索引失效 → 修复 SQL
   - rows 太大 → 添加 LIMIT 或优化条件
   - Using filesort → 优化 ORDER BY
   - Using temporary → 检查 GROUP BY

5️⃣ 验证优化效果
   再次 EXPLAIN，对比 rows 和 type
```

---

**17. 覆盖索引的实战应用？**

**场景：分页查询优化**

```sql
-- ❌ 慢查询：需要回表
SELECT * FROM orders WHERE user_id = 123 ORDER BY id LIMIT 1000000, 10;

-- ✅ 优化：使用覆盖索引先获取 ID，再关联查询
SELECT o.* FROM orders o
INNER JOIN (
    SELECT id FROM orders WHERE user_id = 123 ORDER BY id LIMIT 1000000, 10
) AS t ON o.id = t.id;
```

**原理**：子查询只用索引列（覆盖索引），避免回表，大幅减少扫描行数。

---

**18. Join 优化的核心原则？**

**1. 小表驱动大表**
```sql
-- ✅ 正确
SELECT * FROM users u    -- 10 万行
JOIN orders o ON u.id = o.user_id;  -- 50 万行

-- ❌ 错误
SELECT * FROM orders o  -- 50 万行
JOIN users u ON o.user_id = u.id;   -- 10 万行
```

**2. 在被驱动表的 Join 字段上加索引**
```sql
-- 在 orders.user_id 上建索引
CREATE INDEX idx_user_id ON orders(user_id);
```

**3. 选择合适的 Join 类型**
- **INNER JOIN**：性能最优，优化器可自由选择驱动表
- **LEFT JOIN**：左表必须是驱动表
- **STRAIGHT_JOIN**：强制左表为驱动表

---

**19. COUNT(*) 的优化方法？**

**方案 1：近似值（适合允许误差）**
```sql
SHOW TABLE STATUS LIKE 'table_name';
```

**方案 2：维护计数表（最准确）**
```sql
CREATE TABLE table_count (table_name VARCHAR(50) PRIMARY KEY, row_count INT);
-- 每次增删改时更新计数
```

**方案 3：使用 Redis 缓存（允许短暂不一致）**

---

**20. EXISTS vs IN 的选择？**

| 场景 | 推荐写法 | 原因 |
|------|---------|------|
| **外表小，内表大** | `EXISTS` | 外层循环次数少，内层用索引查找 |
| **外表大，内表小** | `IN` | 内表结果集小，加载到内存做 Hash 查找 |
| **NOT IN（可能有 NULL）** | **必须用 NOT EXISTS** | `NOT IN` 遇到 NULL 返回空结果 |

---

## 📝 面试准备清单

**必背概念**：
- [ ] B+ 树 vs B 树 vs 哈希表
- [ ] 聚簇索引 vs 非聚簇索引
- [ ] 覆盖索引、回表查询
- [ ] 最左前缀原则、索引失效场景
- [ ] 事务 ACID、MVCC 原理
- [ ] RC vs RR 隔离级别
- [ ] Record Lock、Gap Lock、Next-Key Lock
- [ ] Redo Log vs Binlog、两阶段提交
- [ ] 主从复制模式
- [ ] 小表驱动大表、被驱动表加索引

**高频参数**：
- [ ] `innodb_buffer_pool_size`：50-70% 物理内存
- [ ] `innodb_flush_log_at_trx_commit`：1（最安全）
- [ ] `sync_binlog`：1（最安全）
- [ ] `innodb_io_capacity`：SSD 2000-5000
- [ ] `innodb_lock_wait_timeout`：10-50 秒
